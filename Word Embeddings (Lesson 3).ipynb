{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Погружения слов (word embeddings)\n",
    "\n",
    "Погружение, или веторное представление слов (word embeddings) определяется как общее название различных методов языкового моделирования и обучения признаков, применяемых в обработке естетвенного языка, когда слова или фразы отображаются а векторы вещественных чисел.\n",
    "\n",
    "Погружения слов - это способ преобразования текстового представления слов в численные векторы, допускащие анализ стандартными алгоритмами машинного обучения, принимающими на вход числа.\n",
    "\n",
    "Простейший вид погружения слов - унитарное кодирование (one hot encoding).\n",
    "\n",
    "Основная проблема унитарного кодирования в том, что нет никаких способов представить сходство слов. В любом заданном корпусе текстов мы ожидаем, что между словами \"кошка\" и \"собака\" есть какое-то сходство. Сходство векторов вычисляется с помощью скалярного произведения, т.е. суммы произведений соответствующих элементов. В случае унитарного кодирования скалярное произведение будет равно нулю.\n",
    "\n",
    "Для преодоления ограничений унитарного кодирования в NLP долгое время использовалась идея векторизации текста с использованием документа в качестве контекста. Это подходы:\n",
    "* TF-IDF;\n",
    "* латентно-семантический анализ (LSA);\n",
    "* тематическое моделирование (Topic model);\n",
    "\n",
    "Все эти представления улавливают несколько иную, документно-центрическую идею семантического сходства. Погружения слов отличаются от предшествующих методов применяемых в информационном поиске тем, что слова используются скорее как собственный контекст, что приводит к более естественной форме семантического сходства с точки зрения понимания человеком. В настоящее время погружение слов - общепринятая техника векторизации текста во всех задачах NLP (классификация текстов, кластеризация документов, частеречная разметка, распознавание именованных сущностей, анализ эмоциональной окраски и т.п.).\n",
    "\n",
    "Рассмотрим 2 формы погружения слов:\n",
    "* GloVe\n",
    "* word2vec\n",
    "известные под общим названием *распределенное представление слов*. Эти представления оказались более эффективными, и поэтому широко распространены в среде специалистов по глубокому обучению и NLP.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распределенные представления\n",
    "\n",
    "Распределенное представление - попытка уловить смысл слова путем рассмотрения его связей с другими словами в контексте. \n",
    "\n",
    "Эта идея сформулирована в сл. высказывании лингвиста Дж. Р. Фирта (J.R. Firth):\n",
    "\n",
    "**Мы узнаем слово по компании, с которой оно дружит.**\n",
    "\n",
    "Рассмотрим такие два предложения:\n",
    "* Париж - столица Франции\n",
    "* Берлин - столица Германии\n",
    "\n",
    "Даже если вы совсем не щнаете географию (или русский язык), то все равно нетрудно понять, что пары слов (Парид, Берлин) и (Франция, Германия) как-то связаны и что между соответственными словами связи одинаковы, т.е.\n",
    "\n",
    "*Париж : Франция :: Берлин : Гемания*\n",
    "\n",
    "Следовательно, задача распределенного представления - найти общую функцию $\\phi$ преобразования слова в соответствующий ему вектор, чтобы были справедливы соотношения сл. вида:\n",
    "\n",
    "$\\phi$(Париж) - $\\phi$(Франция) ~ $\\phi$(Берлин) - $\\phi$(Германия)\n",
    "\n",
    "Иными словами, ** цель распределенного представления - преобразовать слова в векторы так, чтобы сходство векторов коррелировало с семантическим сходством слов.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec\n",
    "\n",
    "Группа моделей word2vec была разработана в 2013 году группой исследователей Google под руководством Т. Миколова (Tomas Mikolov). Модели обучаются без учителя на большом корпусе текстов и порождают векторное пространство слов. Размерность пространства погружения word2vec обычно меньше размерности погружения для унитарного кодирования. Кроме того, это пространство погружения плотнее разрежененного погружения при унитарном кодировании.\n",
    "\n",
    "Существуют 2 архитектуры word2vec:\n",
    "* Непрерывный мешок слов (Continuous Bag of Words, CBOW);\n",
    "* skip-граммы.\n",
    "\n",
    "В архитектуре CBOW модель предсказывает текущее слово, если известно окно окружающих его слов. Кроме того, порядок контекстных слов не влияет на предсказание (это допущение мешка слов). В архитектуре skip-грамм модель предсказывает окружающие слова по известному центральному слову. Соглано заявлению авторов, CBOW быстрее, но skip-граммы лучше предсказывают редкие слова.\n",
    "\n",
    "Интересно отметить, что хотя word2vec создает погружения, используемые в моделях глубокого обучения NLP, оба варианта word2vec являются мелкими нейронными сетями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель skip-грамм\n",
    "\n",
    "Модель skip-грамм обучается предсказывать окружение по известному центральному слову.\n",
    "\n",
    "Рассмотрим предложение:\n",
    "\n",
    "* I love green eggs and ham. *\n",
    "\n",
    "В предположении, что размер окна 3, предложение можно разложить на пары (контекст, слово):\n",
    "\n",
    "* ([I, green], love)\n",
    "* ([love, eggs], green)\n",
    "* ([green, and], eggs)\n",
    "...\n",
    "\n",
    "Поскольку модель skip-грамм предсказывает контекстные слова по центральному, мы можем преобразовать этот набор данных в набор пар *(вход; выход)*. То есть, зная входное слово, мы ожидаем, что модель skip-грамм предскажет соответствующее выходное:\n",
    "\n",
    "*(love, I), (love, green), (green, love), (green, eggs), (eggs, green), (eggs, and), ...*\n",
    "\n",
    "Также, можно сгенерировать дополнительные **отрицательные** примеры, объединяя в пару каждое входое слово со случайным словом из словаря, например:\n",
    "\n",
    "*(love, Sam), (love, zebra), (green, thing), ...*\n",
    "\n",
    "Наконец, мы генерируем положительные и отрицательные примеры для классификатора:\n",
    "\n",
    "*((love, I),1), ((love, green),1), ..., ((love, zebra),0), ((green, thing),0) ...*\n",
    "\n",
    "Теперь можно обучить классификатор, принимающий вектор слов и контекстный вектор и предсказывает 0, или 1 в зависимости от того, какой пример видит: положительный или отрицательный. Результатом обучения сети являются веса слоя погружения слов (серый блок): \n",
    "\n",
    "![](img/word2vec-pic1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем построение skip-грамм модели в Keras.\n",
    "\n",
    "Пусть размер словаря равен 5000, размер выходного пространста погружения 300, размер окна 1 (последующее и предыдущее слова). Импортируем нужные модули:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Merge\n",
    "from keras.layers.core import Dense, Reshape\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "\n",
    "vocab_size = 5000\n",
    "embed_size = 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем последовательную модель *слова*. Входом модели являются идентификаторы слов в словаре. Весам погружений первоначально присваиваются небольшие случайно выбранные значения. В процессе обучения модель будет обновлять веса, применяя алгоритм обратного распространения ошибки. Следующий слой адаптирует форму входа под размер погружения:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_model = Sequential()\n",
    "word_model.add(Embedding(vocab_size, embed_size,\n",
    "                         embeddings_initializer=\"glorot_uniform\",\n",
    "                         input_length=1))\n",
    "word_model.add(Reshape((embed_size,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также нужна еще одна модель для контекстных слов. Для каждой пары skip-грамм мы имеем одно контекстное слово, соответствующее целевому слову, так что эта модель идентична модели слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_model = Sequential()\n",
    "context_model.add(Embedding(vocab_size, embed_size,\n",
    "                            embeddings_initializer=\"glorot_uniform\",\n",
    "                            input_length=1))\n",
    "context_model.add(Reshape((embed_size,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выходе обеих моделей получаются векторы размера \n",
    "    embed_size.\n",
    "Их скалярное произведение подается на вход плотному слою с сигмоидной функцией активации, который порождает один выход. Сигмоида преобразует аргумент в число из диапазона [0;1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oleg-\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Merge([word_model, context_model], mode=\"dot\", dot_axes=0))\n",
    "model.add(Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_layer = model.layers[0]\n",
    "word_model = merge_layer.layers[0]\n",
    "word_embed_layer = word_model.layers[0]\n",
    "weights = word_embed_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве функции потерь используется mean_squared_error; идея в том, чтобы минимизировать скалярное произведение для положительных примеров и максимизировать для отрицательных.\n",
    "\n",
    "Keras предоставляет функцию для извлечения skip-грамм из текста, преобразованного в список индексов слов. Ниже приведен пример использования для ивлечения первых 10 из 56 сгенерированных skip-грамм (положительных и отрицательных). Импортируем модули и инициализируем подлежащий анализу текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import *\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "text = \"I love green eggs and ham .\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявляем объект для выделения лексем и пропускаем через него текст. Получается список лексем: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объект tokenizer создает словарь, сопоставляющий каждому уникальному слову целочисленный идентификатор, и делает его доступным через атрибут word_index. Мы читаем этот атрибут и создаем 2 таблицы соответствия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2id = tokenizer.word_index\n",
    "id2word = {v:k for k, v in word2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, входной список слов преобразуется в список идентификаторов и передается функци  skipgrams. Затем мы печатаем первые 10 из 56 сгенерированных skip-грамм (пара, метка):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 56\n",
      "(love (2), ham (6)) -> 1\n",
      "(ham (6), and (5)) -> 1\n",
      "(i (1), and (5)) -> 1\n",
      "(ham (6), and (5)) -> 0\n",
      "(ham (6), green (3)) -> 0\n",
      "(i (1), love (2)) -> 1\n",
      "(i (1), eggs (4)) -> 1\n",
      "(eggs (4), green (3)) -> 1\n",
      "(ham (6), and (5)) -> 0\n",
      "(green (3), love (2)) -> 1\n"
     ]
    }
   ],
   "source": [
    "wids = [word2id[w] for w in text_to_word_sequence(text)]\n",
    "pairs, labels = skipgrams(wids, len(word2id))\n",
    "print(len(pairs), len(labels))\n",
    "for i in range(10):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
    "        id2word[pairs[i][0]], pairs[i][0], \n",
    "        id2word[pairs[i][1]], pairs[i][1],\n",
    "        labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция skip-grams производит случайную выборку из множества всевозможых положительных примеров, поэтому результаты могут отличаться при новом запуске. С увеличением размера входного текста вероятность выбрать пары не связанных между собой слов возрастает. В нашем примере текст очень короткий, поэтому высоки шансы, что будут сгенерированы положительные примеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель CBOW\n",
    "\n",
    "Теперь рассмотрим модель CBOW из семейства word2vec. Она предсказывает слово по известным контекстным словам. Таким образом, для первого кортежа из примера ниже CBOW должна предсказать слово *love*, зная контекстные слова *I* и *green*:\n",
    "\n",
    "* ([I, green], love)\n",
    "* ([love, eggs], green)\n",
    "* ([green, and], eggs)\n",
    "* ...\n",
    "\n",
    "Как и модель skip-грамм, модель CBOW представляет собой классификатор, получающий на входе контекстные слова и предказывающий целевое слово. Но архитектура его проще чем в модели skip-грамм. Входными данными модели являются идентификаторы контекстных слов. Они поступают на вход слоя погружения, веса которого инициализируются небольшими случайными значениями. Этот слой преобразует каждый идентификатор в вектор размера embed_size. Следовательно, каждая строка входного контекста преобразуется в матрицу размера (2\\*windows_size, embed_size). Затем матрица подается на вход слоя lambda, который вычисляет среднее по всем погружениям. Полученная величина передается плотном слою, который создает плотный вектор размера vocab_size для каждой строки. В качестве функции активации используется softmax, которая возвращает вероятность, равную максимальному элементу выходного вектора. Идентификатор с максимальой вероятностью соответствует целевому слову.\n",
    "\n",
    "![](img/word2vec-pic2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим код модели на Keras. \n",
    "\n",
    "Размер словаря 5000, размер выходного пространства погружения 300, размер контекстного окна 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Lambda\n",
    "from keras.layers.embeddings import Embedding\n",
    "import keras.backend as K\n",
    "\n",
    "vocab_size = 5000\n",
    "embed_size = 300\n",
    "window_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим последовательную модель, в которую включаем слой погружения с весами, инициализированными малыми случайными значениями. Отметим, что длина входа input_length этого слоя равна числу контекстных слов. Каждое контекстное слово подается на вход слоя, и веса обновляются в процессе обратного распространения. На выходе слоя получается матрица погружений контекстных слов, которая усредняется в один вектор (на каждую строку входа) слоем lambda. Наконец, плотный слой преобразует строки в плотный вектор размера vocab_size. Целевым словом будет то, для которого вероятность идентификатора в плотном выходном векторе максимальна.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embed_size, \n",
    "                    embeddings_initializer='glorot_uniform',\n",
    "                    input_length=window_size*2))\n",
    "model.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)))\n",
    "model.add(Dense(vocab_size, kernel_initializer='glorot_uniform', \n",
    "                activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adadelta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве функции потерь используется категориальна кроссэнтропия - типичный выбор для случая, когда категорий две или больше (в нашем случае vocab_size).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлечение погружений word2vec из модели\n",
    "\n",
    "Обе модели семейства word2vec можно свести к задаче классификации, хотя сама эта задача нас не интересует. А интересен нам побочный эффект классификации - матрица весов, преобразующая слово из словаря в плотнгое распределенное представление низкой размерности.\n",
    "\n",
    "Есть немало примеров того как распределенное представление выявляет удивительную синтаксичскую и семантическую информацию. \n",
    "Векторы, соединяющие слова, имеющие примерно одинаковый смысл, но относящиеся к разным полам, прблизительно параллельны в редуцированном пространстве и можно получить согласующиеся с интуицией результаты проводя арифметические действия над векторами слов.\n",
    "\n",
    "![](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/img/Mikolov-GenderVecs.png)\n",
    "\n",
    "Интуитивно кажется, что процесс обучение привносит достаточно информации во внутреннюю кодировку чтобы предсказать выходное слово, встречающееся в контексте входного. Поэтому точки, представляющие слова в этом пространстве располагаются ближе к точкам слов, с которыми они встречабися совестно. В результате походие слова образуют кластеры. И слова, встречающиеся вместе с похожими словами, тоже образуют кластеры. Следовательно, векторы, соединяющие точки, представляющие семантически связанные слова в распределенном представлении, демонстрируют регулярное поведение.\n",
    "\n",
    "Keras предоставляет средства для извлечения весов из обученных моделей. Например, для skip-грамм веса слоя погружения можно получить сл. образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_layer = model.layers[0]\n",
    "word_model = merge_layer.layers[0]\n",
    "word_embed_layer = word_model.layers[0]\n",
    "weights = word_embed_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае CBOW для получения весов достаточно одной строчки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обоих случах матрица весов имеет размер vocab_size x embed_size. Для вычисления распределенного представления слова из словаря нужно построить унитарный вектор, записав 1 в элемент вектора размера vocab_size с индексом, равным идентификатору слова и умножить его на матрицу весов, получив в результате вектор погружения размера embed_size.\n",
    "\n",
    "Визуализация погружений слов, выполненая Christopher Olah:\n",
    "![](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/img/Socher-ImageClass-tSNE.png)\n",
    "\n",
    "Для этого было произведено понижение размерности до 2 измерений и использовался метод t-SNE. Точки, соответствующие похожим типа сущностей образуют кластер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сторонние реализации word2vec\n",
    "\n",
    "На данном этапе вы понимаете работу моделей skip-грамм и CBOW (и как построить их реализацию с помощью Keras). Однако, существуют готовые реализации word2vec и в предположении что ваша задача не слишком сложна и не слишком отличается от типичной, имеет смысл воспользоваться одной из них и не изобретать велосипед.\n",
    "\n",
    "Одна из таких реализаций word2vec - библоитека gensim (https://radimrehurek.com/gensim/). Интеграция gensim и Keras достаточно распространенная практика.\n",
    "\n",
    "Рассмотрим пример, как построить модель word2vec с помощью gensim и обучить её на тексте из корпуса text8 (link: mattmahoney.net/dc/text8.zip ).\n",
    "Файл содержит 17 миллионов слов, взятых из статей википедии. Текст был подвергнут очистке - удалению разметки, знаков препинания и символов отличающихся от ASCII. Первые 100 миллионов знаков очищенного текста и составили корпус text8/ Он часто используется для примера модели word2vec, потому что обучение на нем проходит быстро и дает хорошие результаты.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oleg-\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "import os\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем поток слов из корпуса text8, разбивая его на предложения по 50 слов в каждом. Библиотека gensim имеет встроенный обработчик text8, который делает нечто подобное. Но мы хотим построить модель для любого корпуса (предпочтительно большого), который может и не помещаться в памяти, поэтому продемонстрируем порождение этих предложений с помозью генератора Python.\n",
    "\n",
    "Класс Text8Sentences порождает предложения по maxlen слов в каждом из файла text8. В данном случае мы читакм весь файл в память, но при обходе файлов, находящихся в нескольких каталога, генератор позволяет загрузить в память часть данных обработать её и отдать вызывающей стороне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Text8Sentences(object):\n",
    "    def __init__(self, fname, maxlen):\n",
    "        self.fname = fname\n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "    def __iter__(self):\n",
    "        with open(os.path.join(DATA_DIR, \"text8\"), \"rb\") as ftext:\n",
    "            tmp = str(ftext.read())\n",
    "            text = tmp.split(\" \")\n",
    "            words = []\n",
    "            for word in text:\n",
    "                if len(words) >= self.maxlen:\n",
    "                    yield words\n",
    "                    words = []\n",
    "                words.append(word)\n",
    "            yield words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь напишем функции вызова. Активируем механизм протокодирования для уведомления о ходе обработки. \n",
    "\n",
    "Затем создадим экземпляр класса Text8Sentences и обучим модель из этого набора данных. Мы задали размер векторов погружения 300 и рассматриваем слова, встречающиеся в корпусе не менее 30 раз. Размер окна по умолчанию равен 5, поэтому контекстом для слова $w_i$ будут слова: $w_{i-5}, w_{i-4}, w_{i-3}, w_{i-2}, w_{i-1}, w_{i+1}, w_{i+2}, w_{i+3}, w_{i+4}, w_{i+5}$. По умолчанию создается модель CBOW, но это можно изменить, задав параметр sg=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-11 19:22:14,871 : INFO : collecting all words and their counts\n",
      "2017-11-11 19:22:21,403 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-11-11 19:22:21,936 : INFO : PROGRESS: at sentence #10000, processed 500000 words, keeping 33464 word types\n",
      "2017-11-11 19:22:22,490 : INFO : PROGRESS: at sentence #20000, processed 1000000 words, keeping 52755 word types\n",
      "2017-11-11 19:22:23,005 : INFO : PROGRESS: at sentence #30000, processed 1500000 words, keeping 65589 word types\n",
      "2017-11-11 19:22:23,488 : INFO : PROGRESS: at sentence #40000, processed 2000000 words, keeping 78383 word types\n",
      "2017-11-11 19:22:24,083 : INFO : PROGRESS: at sentence #50000, processed 2500000 words, keeping 88008 word types\n",
      "2017-11-11 19:22:24,775 : INFO : PROGRESS: at sentence #60000, processed 3000000 words, keeping 96645 word types\n",
      "2017-11-11 19:22:25,322 : INFO : PROGRESS: at sentence #70000, processed 3500000 words, keeping 104309 word types\n",
      "2017-11-11 19:22:25,821 : INFO : PROGRESS: at sentence #80000, processed 4000000 words, keeping 111461 word types\n",
      "2017-11-11 19:22:26,343 : INFO : PROGRESS: at sentence #90000, processed 4500000 words, keeping 118752 word types\n",
      "2017-11-11 19:22:26,783 : INFO : PROGRESS: at sentence #100000, processed 5000000 words, keeping 125355 word types\n",
      "2017-11-11 19:22:27,256 : INFO : PROGRESS: at sentence #110000, processed 5500000 words, keeping 133141 word types\n",
      "2017-11-11 19:22:27,733 : INFO : PROGRESS: at sentence #120000, processed 6000000 words, keeping 139566 word types\n",
      "2017-11-11 19:22:28,084 : INFO : PROGRESS: at sentence #130000, processed 6500000 words, keeping 145782 word types\n",
      "2017-11-11 19:22:28,457 : INFO : PROGRESS: at sentence #140000, processed 7000000 words, keeping 151934 word types\n",
      "2017-11-11 19:22:28,867 : INFO : PROGRESS: at sentence #150000, processed 7500000 words, keeping 158046 word types\n",
      "2017-11-11 19:22:29,342 : INFO : PROGRESS: at sentence #160000, processed 8000000 words, keeping 164115 word types\n",
      "2017-11-11 19:22:29,736 : INFO : PROGRESS: at sentence #170000, processed 8500000 words, keeping 171256 word types\n",
      "2017-11-11 19:22:30,225 : INFO : PROGRESS: at sentence #180000, processed 9000000 words, keeping 178163 word types\n",
      "2017-11-11 19:22:30,589 : INFO : PROGRESS: at sentence #190000, processed 9500000 words, keeping 184129 word types\n",
      "2017-11-11 19:22:30,985 : INFO : PROGRESS: at sentence #200000, processed 10000000 words, keeping 189075 word types\n",
      "2017-11-11 19:22:31,470 : INFO : PROGRESS: at sentence #210000, processed 10500000 words, keeping 194511 word types\n",
      "2017-11-11 19:22:31,977 : INFO : PROGRESS: at sentence #220000, processed 11000000 words, keeping 198758 word types\n",
      "2017-11-11 19:22:32,493 : INFO : PROGRESS: at sentence #230000, processed 11500000 words, keeping 203441 word types\n",
      "2017-11-11 19:22:33,007 : INFO : PROGRESS: at sentence #240000, processed 12000000 words, keeping 207895 word types\n",
      "2017-11-11 19:22:33,457 : INFO : PROGRESS: at sentence #250000, processed 12500000 words, keeping 212668 word types\n",
      "2017-11-11 19:22:33,873 : INFO : PROGRESS: at sentence #260000, processed 13000000 words, keeping 217128 word types\n",
      "2017-11-11 19:22:34,257 : INFO : PROGRESS: at sentence #270000, processed 13500000 words, keeping 221416 word types\n",
      "2017-11-11 19:22:34,628 : INFO : PROGRESS: at sentence #280000, processed 14000000 words, keeping 226855 word types\n",
      "2017-11-11 19:22:34,976 : INFO : PROGRESS: at sentence #290000, processed 14500000 words, keeping 231424 word types\n",
      "2017-11-11 19:22:35,355 : INFO : PROGRESS: at sentence #300000, processed 15000000 words, keeping 237391 word types\n",
      "2017-11-11 19:22:35,724 : INFO : PROGRESS: at sentence #310000, processed 15500000 words, keeping 241697 word types\n",
      "2017-11-11 19:22:36,109 : INFO : PROGRESS: at sentence #320000, processed 16000000 words, keeping 245649 word types\n",
      "2017-11-11 19:22:36,465 : INFO : PROGRESS: at sentence #330000, processed 16500000 words, keeping 249621 word types\n",
      "2017-11-11 19:22:36,823 : INFO : PROGRESS: at sentence #340000, processed 17000000 words, keeping 253834 word types\n",
      "2017-11-11 19:22:37,185 : INFO : collected 253855 word types from a corpus of 17005208 raw words and 340105 sentences\n",
      "2017-11-11 19:22:37,188 : INFO : Loading a fresh vocabulary\n",
      "2017-11-11 19:22:44,829 : INFO : min_count=30 retains 25097 unique words (9% of original 253855, drops 228758)\n",
      "2017-11-11 19:22:44,831 : INFO : min_count=30 leaves 16191059 word corpus (95% of original 17005208, drops 814149)\n",
      "2017-11-11 19:22:45,044 : INFO : deleting the raw counts dictionary of 253855 items\n",
      "2017-11-11 19:22:45,244 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2017-11-11 19:22:45,244 : INFO : downsampling leaves estimated 11928483 word corpus (73.7% of prior 16191059)\n",
      "2017-11-11 19:22:45,256 : INFO : estimated required memory for 25097 words and 300 dimensions: 72781300 bytes\n",
      "2017-11-11 19:22:45,534 : INFO : resetting layer weights\n",
      "2017-11-11 19:22:46,286 : INFO : training model with 3 workers on 25097 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-11-11 19:22:52,472 : INFO : PROGRESS: at 0.01% examples, 1396 words/s, in_qsize 3, out_qsize 0\n",
      "2017-11-11 19:22:53,480 : INFO : PROGRESS: at 0.46% examples, 43488 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:22:54,491 : INFO : PROGRESS: at 0.98% examples, 79081 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:22:55,496 : INFO : PROGRESS: at 1.52% examples, 107086 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:22:56,505 : INFO : PROGRESS: at 2.06% examples, 129690 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:22:57,506 : INFO : PROGRESS: at 2.55% examples, 145315 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:22:58,555 : INFO : PROGRESS: at 3.07% examples, 158914 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:22:59,556 : INFO : PROGRESS: at 3.56% examples, 169988 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:00,581 : INFO : PROGRESS: at 4.06% examples, 178788 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:23:01,592 : INFO : PROGRESS: at 4.59% examples, 188338 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:02,618 : INFO : PROGRESS: at 5.14% examples, 197278 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:23:03,619 : INFO : PROGRESS: at 5.70% examples, 206006 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:23:04,661 : INFO : PROGRESS: at 6.25% examples, 212515 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:05,678 : INFO : PROGRESS: at 6.80% examples, 218815 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:06,696 : INFO : PROGRESS: at 7.37% examples, 225142 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:07,713 : INFO : PROGRESS: at 7.94% examples, 230455 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:23:08,729 : INFO : PROGRESS: at 8.49% examples, 234916 words/s, in_qsize 5, out_qsize 1\n",
      "2017-11-11 19:23:09,755 : INFO : PROGRESS: at 9.04% examples, 238927 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:10,770 : INFO : PROGRESS: at 9.59% examples, 242377 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:11,784 : INFO : PROGRESS: at 10.15% examples, 246181 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:12,795 : INFO : PROGRESS: at 10.73% examples, 249826 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:13,796 : INFO : PROGRESS: at 11.30% examples, 253490 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:14,803 : INFO : PROGRESS: at 11.88% examples, 256705 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:15,795 : INFO : PROGRESS: at 12.42% examples, 258980 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:16,828 : INFO : PROGRESS: at 13.00% examples, 261639 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:23:17,828 : INFO : PROGRESS: at 13.57% examples, 264257 words/s, in_qsize 4, out_qsize 1\n",
      "2017-11-11 19:23:18,860 : INFO : PROGRESS: at 14.15% examples, 266717 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:19,900 : INFO : PROGRESS: at 14.64% examples, 267331 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:20,915 : INFO : PROGRESS: at 15.18% examples, 268495 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:21,947 : INFO : PROGRESS: at 15.75% examples, 269976 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:22,965 : INFO : PROGRESS: at 16.34% examples, 272055 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:23,983 : INFO : PROGRESS: at 16.92% examples, 274081 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:24,986 : INFO : PROGRESS: at 17.47% examples, 275267 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:26,006 : INFO : PROGRESS: at 17.98% examples, 276062 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:27,017 : INFO : PROGRESS: at 18.54% examples, 277249 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:28,041 : INFO : PROGRESS: at 19.14% examples, 279028 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:23:29,046 : INFO : PROGRESS: at 19.71% examples, 280416 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:23:33,082 : INFO : PROGRESS: at 19.98% examples, 259325 words/s, in_qsize 0, out_qsize 1\n",
      "2017-11-11 19:23:34,104 : INFO : PROGRESS: at 20.37% examples, 258691 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:23:35,113 : INFO : PROGRESS: at 20.93% examples, 260216 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:36,151 : INFO : PROGRESS: at 21.51% examples, 261527 words/s, in_qsize 6, out_qsize 1\n",
      "2017-11-11 19:23:37,149 : INFO : PROGRESS: at 22.09% examples, 263063 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:23:38,169 : INFO : PROGRESS: at 22.66% examples, 264530 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:39,176 : INFO : PROGRESS: at 23.23% examples, 265899 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:40,199 : INFO : PROGRESS: at 23.79% examples, 267136 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:41,192 : INFO : PROGRESS: at 24.36% examples, 268384 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:23:42,221 : INFO : PROGRESS: at 24.91% examples, 269515 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:43,240 : INFO : PROGRESS: at 25.47% examples, 270670 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:44,251 : INFO : PROGRESS: at 26.02% examples, 271609 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:45,278 : INFO : PROGRESS: at 26.57% examples, 272568 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:46,288 : INFO : PROGRESS: at 27.14% examples, 273765 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:47,304 : INFO : PROGRESS: at 27.72% examples, 274883 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:48,344 : INFO : PROGRESS: at 28.30% examples, 275842 words/s, in_qsize 5, out_qsize 1\n",
      "2017-11-11 19:23:49,349 : INFO : PROGRESS: at 28.87% examples, 276954 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:23:50,339 : INFO : PROGRESS: at 29.44% examples, 277929 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:51,380 : INFO : PROGRESS: at 30.01% examples, 278845 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:52,399 : INFO : PROGRESS: at 30.59% examples, 279779 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:53,415 : INFO : PROGRESS: at 31.14% examples, 280490 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:54,432 : INFO : PROGRESS: at 31.72% examples, 281367 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:55,439 : INFO : PROGRESS: at 32.27% examples, 282067 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:56,460 : INFO : PROGRESS: at 32.80% examples, 282490 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:23:57,470 : INFO : PROGRESS: at 33.37% examples, 283220 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:58,475 : INFO : PROGRESS: at 33.92% examples, 283865 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:23:59,471 : INFO : PROGRESS: at 34.48% examples, 284611 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:00,498 : INFO : PROGRESS: at 35.07% examples, 285397 words/s, in_qsize 6, out_qsize 1\n",
      "2017-11-11 19:24:01,509 : INFO : PROGRESS: at 35.65% examples, 285988 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:02,533 : INFO : PROGRESS: at 36.19% examples, 286370 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:03,535 : INFO : PROGRESS: at 36.77% examples, 287097 words/s, in_qsize 4, out_qsize 1\n",
      "2017-11-11 19:24:04,559 : INFO : PROGRESS: at 37.31% examples, 287467 words/s, in_qsize 6, out_qsize 1\n",
      "2017-11-11 19:24:05,564 : INFO : PROGRESS: at 37.79% examples, 287436 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:06,569 : INFO : PROGRESS: at 38.33% examples, 287859 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:07,581 : INFO : PROGRESS: at 38.85% examples, 288042 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:08,593 : INFO : PROGRESS: at 39.29% examples, 287724 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:09,612 : INFO : PROGRESS: at 39.81% examples, 287859 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:13,521 : INFO : PROGRESS: at 39.98% examples, 275996 words/s, in_qsize 0, out_qsize 2\n",
      "2017-11-11 19:24:14,574 : INFO : PROGRESS: at 40.05% examples, 273164 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:15,577 : INFO : PROGRESS: at 40.45% examples, 272785 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:16,583 : INFO : PROGRESS: at 40.94% examples, 272986 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:17,596 : INFO : PROGRESS: at 41.48% examples, 273392 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:18,593 : INFO : PROGRESS: at 42.02% examples, 273888 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:19,621 : INFO : PROGRESS: at 42.59% examples, 274484 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:20,648 : INFO : PROGRESS: at 43.17% examples, 275208 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:21,662 : INFO : PROGRESS: at 43.76% examples, 275983 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:22,692 : INFO : PROGRESS: at 44.35% examples, 276672 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:23,697 : INFO : PROGRESS: at 44.93% examples, 277402 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:24,702 : INFO : PROGRESS: at 45.49% examples, 278040 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:25,720 : INFO : PROGRESS: at 46.09% examples, 278849 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:26,749 : INFO : PROGRESS: at 46.68% examples, 279528 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:27,748 : INFO : PROGRESS: at 47.28% examples, 280346 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:28,749 : INFO : PROGRESS: at 47.86% examples, 280942 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:29,767 : INFO : PROGRESS: at 48.43% examples, 281532 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:30,761 : INFO : PROGRESS: at 49.00% examples, 282090 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:31,796 : INFO : PROGRESS: at 49.60% examples, 282765 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:32,794 : INFO : PROGRESS: at 50.16% examples, 283291 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:33,819 : INFO : PROGRESS: at 50.75% examples, 283859 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:34,827 : INFO : PROGRESS: at 51.33% examples, 284425 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:35,821 : INFO : PROGRESS: at 51.90% examples, 284958 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:36,839 : INFO : PROGRESS: at 52.48% examples, 285460 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:37,859 : INFO : PROGRESS: at 53.03% examples, 285840 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:38,847 : INFO : PROGRESS: at 53.61% examples, 286369 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:39,864 : INFO : PROGRESS: at 54.20% examples, 286956 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:40,887 : INFO : PROGRESS: at 54.67% examples, 286865 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:41,891 : INFO : PROGRESS: at 55.19% examples, 286988 words/s, in_qsize 5, out_qsize 1\n",
      "2017-11-11 19:24:42,890 : INFO : PROGRESS: at 55.76% examples, 287353 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:43,950 : INFO : PROGRESS: at 56.29% examples, 287462 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:44,956 : INFO : PROGRESS: at 56.86% examples, 287921 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:45,954 : INFO : PROGRESS: at 57.42% examples, 288241 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:46,990 : INFO : PROGRESS: at 57.99% examples, 288653 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:47,994 : INFO : PROGRESS: at 58.58% examples, 289130 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:49,007 : INFO : PROGRESS: at 59.17% examples, 289600 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:50,007 : INFO : PROGRESS: at 59.58% examples, 289205 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:51,372 : INFO : PROGRESS: at 59.90% examples, 287525 words/s, in_qsize 3, out_qsize 2\n",
      "2017-11-11 19:24:54,598 : INFO : PROGRESS: at 59.97% examples, 280611 words/s, in_qsize 0, out_qsize 2\n",
      "2017-11-11 19:24:55,612 : INFO : PROGRESS: at 60.37% examples, 280273 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:56,623 : INFO : PROGRESS: at 60.92% examples, 280617 words/s, in_qsize 4, out_qsize 1\n",
      "2017-11-11 19:24:57,629 : INFO : PROGRESS: at 61.46% examples, 280854 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:24:58,654 : INFO : PROGRESS: at 62.04% examples, 281262 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:24:59,673 : INFO : PROGRESS: at 62.63% examples, 281725 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:00,706 : INFO : PROGRESS: at 63.20% examples, 282119 words/s, in_qsize 5, out_qsize 1\n",
      "2017-11-11 19:25:01,749 : INFO : PROGRESS: at 63.73% examples, 282295 words/s, in_qsize 5, out_qsize 1\n",
      "2017-11-11 19:25:02,752 : INFO : PROGRESS: at 64.23% examples, 282372 words/s, in_qsize 4, out_qsize 1\n",
      "2017-11-11 19:25:03,746 : INFO : PROGRESS: at 64.80% examples, 282861 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:04,747 : INFO : PROGRESS: at 65.37% examples, 283254 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:05,748 : INFO : PROGRESS: at 65.92% examples, 283624 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:06,771 : INFO : PROGRESS: at 66.49% examples, 283976 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:07,796 : INFO : PROGRESS: at 67.05% examples, 284363 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:08,799 : INFO : PROGRESS: at 67.60% examples, 284696 words/s, in_qsize 6, out_qsize 1\n",
      "2017-11-11 19:25:09,805 : INFO : PROGRESS: at 68.12% examples, 284846 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:10,816 : INFO : PROGRESS: at 68.61% examples, 284915 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:11,845 : INFO : PROGRESS: at 69.10% examples, 284880 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:12,865 : INFO : PROGRESS: at 69.53% examples, 284674 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:13,868 : INFO : PROGRESS: at 70.05% examples, 284818 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:14,886 : INFO : PROGRESS: at 70.57% examples, 284968 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:15,893 : INFO : PROGRESS: at 71.10% examples, 285177 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:16,891 : INFO : PROGRESS: at 71.65% examples, 285476 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:17,909 : INFO : PROGRESS: at 72.22% examples, 285845 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:18,914 : INFO : PROGRESS: at 72.75% examples, 286039 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:19,920 : INFO : PROGRESS: at 73.32% examples, 286360 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:20,922 : INFO : PROGRESS: at 73.87% examples, 286648 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:21,933 : INFO : PROGRESS: at 74.42% examples, 286922 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:22,948 : INFO : PROGRESS: at 75.00% examples, 287259 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:23,955 : INFO : PROGRESS: at 75.59% examples, 287555 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:24,957 : INFO : PROGRESS: at 76.15% examples, 287833 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:25,972 : INFO : PROGRESS: at 76.74% examples, 288214 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:26,981 : INFO : PROGRESS: at 77.32% examples, 288541 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:28,002 : INFO : PROGRESS: at 77.92% examples, 288933 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:29,031 : INFO : PROGRESS: at 78.53% examples, 289331 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:30,042 : INFO : PROGRESS: at 79.10% examples, 289628 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:31,042 : INFO : PROGRESS: at 79.68% examples, 289918 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:32,061 : INFO : PROGRESS: at 79.95% examples, 289138 words/s, in_qsize 1, out_qsize 0\n",
      "2017-11-11 19:25:35,097 : INFO : PROGRESS: at 79.99% examples, 284016 words/s, in_qsize 0, out_qsize 1\n",
      "2017-11-11 19:25:36,122 : INFO : PROGRESS: at 80.38% examples, 283703 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:37,122 : INFO : PROGRESS: at 80.93% examples, 283961 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:38,123 : INFO : PROGRESS: at 81.50% examples, 284253 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:39,123 : INFO : PROGRESS: at 82.10% examples, 284645 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:40,166 : INFO : PROGRESS: at 82.69% examples, 284962 words/s, in_qsize 6, out_qsize 1\n",
      "2017-11-11 19:25:41,175 : INFO : PROGRESS: at 83.30% examples, 285388 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:42,197 : INFO : PROGRESS: at 83.79% examples, 285386 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:43,202 : INFO : PROGRESS: at 84.21% examples, 285191 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:44,221 : INFO : PROGRESS: at 84.67% examples, 285116 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:45,227 : INFO : PROGRESS: at 85.13% examples, 285041 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:46,249 : INFO : PROGRESS: at 85.64% examples, 285176 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:47,270 : INFO : PROGRESS: at 86.11% examples, 285134 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:48,279 : INFO : PROGRESS: at 86.60% examples, 285150 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:49,300 : INFO : PROGRESS: at 87.11% examples, 285268 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:50,312 : INFO : PROGRESS: at 87.61% examples, 285314 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:51,332 : INFO : PROGRESS: at 88.09% examples, 285287 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:52,354 : INFO : PROGRESS: at 88.48% examples, 284970 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:53,363 : INFO : PROGRESS: at 88.95% examples, 284949 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:54,372 : INFO : PROGRESS: at 89.40% examples, 284842 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:55,420 : INFO : PROGRESS: at 89.89% examples, 284825 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:56,456 : INFO : PROGRESS: at 90.34% examples, 284677 words/s, in_qsize 5, out_qsize 1\n",
      "2017-11-11 19:25:57,475 : INFO : PROGRESS: at 90.74% examples, 284406 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:25:58,491 : INFO : PROGRESS: at 91.16% examples, 284232 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:25:59,505 : INFO : PROGRESS: at 91.57% examples, 284014 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:00,508 : INFO : PROGRESS: at 91.96% examples, 283739 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:01,515 : INFO : PROGRESS: at 92.42% examples, 283680 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:02,523 : INFO : PROGRESS: at 92.94% examples, 283801 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:03,534 : INFO : PROGRESS: at 93.44% examples, 283878 words/s, in_qsize 4, out_qsize 1\n",
      "2017-11-11 19:26:04,535 : INFO : PROGRESS: at 93.92% examples, 283903 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:05,550 : INFO : PROGRESS: at 94.39% examples, 283878 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:06,570 : INFO : PROGRESS: at 94.90% examples, 283958 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:26:07,601 : INFO : PROGRESS: at 95.43% examples, 283995 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:08,605 : INFO : PROGRESS: at 95.97% examples, 284167 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:09,601 : INFO : PROGRESS: at 96.49% examples, 284256 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:10,626 : INFO : PROGRESS: at 97.03% examples, 284435 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:11,643 : INFO : PROGRESS: at 97.59% examples, 284660 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:12,667 : INFO : PROGRESS: at 98.12% examples, 284791 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:13,695 : INFO : PROGRESS: at 98.63% examples, 284820 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:26:14,699 : INFO : PROGRESS: at 99.15% examples, 284927 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:15,721 : INFO : PROGRESS: at 99.69% examples, 285049 words/s, in_qsize 6, out_qsize 0\n",
      "2017-11-11 19:26:16,734 : INFO : PROGRESS: at 99.95% examples, 284408 words/s, in_qsize 5, out_qsize 0\n",
      "2017-11-11 19:26:16,801 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-11-11 19:26:16,808 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-11-11 19:26:16,823 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-11-11 19:26:16,825 : INFO : training on 85026040 raw words (59648659 effective words) took 209.7s, 284451 effective words/s\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "DATA_DIR = \"./data/\"\n",
    "sentences = Text8Sentences(os.path.join(DATA_DIR, \"text8\"), 50)\n",
    "model = word2vec.Word2Vec(sentences, size=300, min_count=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация word2vec производит 2 прохода по данным, сначала строится словарь, затем фактическая модель. За ходом построения модели можно смотреть по логам на консоли.\n",
    "После создания модели нужно нормировать получившиеся векторы. В документации сказано, что это сэкономи много памяти. Обученную модель также можно сохранить на диске:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-11 19:26:35,675 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-11-11 19:26:36,128 : INFO : saving Word2Vec object under word2vec_gensim.bin, separately None\n",
      "2017-11-11 19:26:36,144 : INFO : not storing attribute syn0norm\n",
      "2017-11-11 19:26:36,147 : INFO : not storing attribute cum_table\n",
      "2017-11-11 19:26:38,139 : INFO : saved word2vec_gensim.bin\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)\n",
    "model.save(\"word2vec_gensim.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для загрузки сохраненной модели в память используется сл. метод:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-11 19:27:09,278 : INFO : loading Word2Vec object from word2vec_gensim.bin\n",
      "2017-11-11 19:27:10,096 : INFO : loading wv recursively from word2vec_gensim.bin.wv.* with mmap=None\n",
      "2017-11-11 19:27:10,098 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-11-11 19:27:10,100 : INFO : setting ignored attribute cum_table to None\n",
      "2017-11-11 19:27:10,103 : INFO : loaded word2vec_gensim.bin\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load('word2vec_gensim.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно получить вкторное представление заданного слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.24130631e-02,   2.12733038e-02,   5.32539226e-02,\n",
       "         7.90794790e-02,   6.95266586e-04,  -3.13665979e-02,\n",
       "        -1.94576439e-02,  -2.86075789e-02,  -3.25210169e-02,\n",
       "         6.19053021e-02,   3.46451588e-02,  -3.54732387e-02,\n",
       "        -5.18917553e-02,   5.02903573e-02,  -1.21724293e-01,\n",
       "        -2.84386370e-02,  -6.59237728e-02,  -5.62250018e-02,\n",
       "         4.84467149e-02,  -3.55367010e-05,   7.30938613e-02,\n",
       "         6.97688460e-02,  -8.76506940e-02,  -2.57450044e-02,\n",
       "        -2.36480124e-02,   3.08887241e-03,   9.95956585e-02,\n",
       "         1.96102560e-02,   1.99851189e-02,  -4.70198953e-04,\n",
       "        -7.95919169e-03,   5.65129099e-03,  -2.36462522e-02,\n",
       "         2.26825066e-02,   7.93054849e-02,   3.35591957e-02,\n",
       "         6.78249449e-02,  -1.61220450e-02,  -6.39008135e-02,\n",
       "        -3.52712534e-02,   4.89605553e-02,   7.39221508e-03,\n",
       "        -1.05902469e-02,   5.16011640e-02,  -5.63778505e-02,\n",
       "         2.11923793e-02,   1.21231802e-01,   4.24933098e-02,\n",
       "         1.59606084e-01,   7.76097849e-02,  -2.60720700e-02,\n",
       "         9.16963220e-02,   3.04291421e-03,  -2.30266880e-02,\n",
       "         5.02987839e-02,   6.83460757e-02,   8.20070654e-02,\n",
       "        -1.82815921e-03,  -5.04247770e-02,   3.81864235e-02,\n",
       "        -1.28492108e-02,  -8.69404301e-02,   3.54660675e-02,\n",
       "        -1.51995659e-01,   7.38831758e-02,   1.30126886e-02,\n",
       "        -1.27421673e-02,  -3.98390070e-02,  -2.21085884e-02,\n",
       "         3.19120698e-02,   5.78158675e-03,  -5.07219061e-02,\n",
       "        -1.54948677e-03,  -1.32960714e-02,  -7.17254430e-02,\n",
       "        -1.05707189e-02,  -1.00774445e-01,   2.25738380e-02,\n",
       "        -7.46184886e-02,  -7.21915960e-02,  -1.62014179e-02,\n",
       "        -5.04658371e-02,   1.33830979e-01,   8.67944062e-02,\n",
       "         8.18200335e-02,   4.95627150e-02,   5.15097640e-02,\n",
       "         4.38991040e-02,  -2.68692989e-03,   4.57324348e-02,\n",
       "         5.43523990e-02,  -5.82216941e-02,   3.71979102e-02,\n",
       "         1.41810114e-02,   2.28323275e-03,   2.79373433e-02,\n",
       "         4.54155467e-02,   4.03012335e-02,   7.01926500e-02,\n",
       "        -1.07704930e-01,   2.76738014e-02,  -6.26283363e-02,\n",
       "        -5.07918708e-02,   1.23559600e-02,  -6.08520731e-02,\n",
       "         4.88564484e-02,  -2.19450910e-02,   5.63754477e-02,\n",
       "        -1.55053847e-02,  -2.42873989e-06,   2.73238719e-02,\n",
       "        -1.58803873e-02,  -3.26282158e-02,   1.55062322e-02,\n",
       "         1.05346497e-02,  -7.19779581e-02,  -7.72360340e-02,\n",
       "         7.96070322e-02,  -2.15469841e-02,  -4.90225926e-02,\n",
       "         1.28619345e-02,  -4.35327925e-02,  -9.91182998e-02,\n",
       "         1.10370040e-01,   1.24185169e-02,  -6.40227944e-02,\n",
       "         4.52583916e-02,   3.55049819e-02,   4.28055786e-02,\n",
       "        -9.27735865e-03,  -6.31363690e-02,  -9.05167758e-02,\n",
       "        -6.14111051e-02,   5.30247837e-02,   5.17473370e-02,\n",
       "        -9.42934584e-03,  -9.27418619e-02,   6.58319294e-02,\n",
       "        -1.37822079e-02,   1.51069546e-02,   6.89414293e-02,\n",
       "         5.06901033e-02,  -1.00011952e-01,   1.41719962e-02,\n",
       "        -5.09092733e-02,   1.33761972e-01,   8.53221957e-03,\n",
       "         1.80223491e-02,  -6.74994141e-02,  -6.30859509e-02,\n",
       "         6.00047819e-02,  -2.76235696e-02,  -4.13422612e-03,\n",
       "         8.55240449e-02,  -9.35110673e-02,  -1.59667328e-01,\n",
       "         7.83248711e-03,   5.11231571e-02,   5.86570008e-03,\n",
       "        -3.84898894e-02,   9.90464166e-02,   1.31082937e-01,\n",
       "         1.61181726e-02,   4.73752767e-02,  -2.37352308e-02,\n",
       "        -3.59833017e-02,   9.88431554e-03,  -5.52354380e-02,\n",
       "         9.15992931e-02,  -8.18772707e-03,  -1.02917828e-01,\n",
       "         3.68846022e-02,   5.92284556e-03,  -8.99356157e-02,\n",
       "        -7.40944073e-02,   2.77732145e-02,  -4.92239594e-02,\n",
       "         4.44718124e-03,   4.28915489e-03,   1.37551746e-03,\n",
       "        -6.82504773e-02,   8.10102373e-02,   4.42323312e-02,\n",
       "        -7.20912144e-02,   1.06101930e-01,   2.88208518e-02,\n",
       "         3.80187966e-02,  -1.92440022e-02,   5.07418923e-02,\n",
       "        -8.56536627e-03,   1.40934549e-02,   3.61202545e-02,\n",
       "         6.52443841e-02,   1.08989783e-01,   7.84035306e-03,\n",
       "         2.82173436e-02,  -5.35069667e-02,   1.05871536e-01,\n",
       "         1.38991967e-01,   6.05848953e-02,  -6.18408509e-02,\n",
       "         7.43796118e-03,   6.06658943e-02,   2.13862713e-02,\n",
       "         4.32164129e-03,   1.26711996e-02,   6.44054189e-02,\n",
       "         2.35525146e-03,  -1.66372713e-02,   1.01226494e-01,\n",
       "        -1.47353917e-01,  -5.07678315e-02,  -1.80737656e-02,\n",
       "         9.45547037e-03,  -8.78646821e-02,   2.77772006e-02,\n",
       "         7.35020936e-02,   4.83672135e-02,   1.21095264e-02,\n",
       "         3.43982093e-02,   1.02254421e-01,  -4.12057561e-04,\n",
       "        -2.70107738e-03,   5.70359454e-02,   1.00685909e-01,\n",
       "         3.57182212e-02,  -5.69396392e-02,  -2.67019756e-02,\n",
       "        -8.43018591e-02,   4.84791920e-02,  -1.16850838e-01,\n",
       "        -1.78117920e-02,  -6.28430545e-02,  -3.13054142e-03,\n",
       "        -9.31327343e-02,   6.78618923e-02,  -2.96646841e-02,\n",
       "        -7.03932866e-02,  -4.92491759e-03,  -1.19329803e-01,\n",
       "         4.54461761e-02,   5.26407287e-02,   9.96003579e-03,\n",
       "         1.50214508e-02,   1.26643092e-04,  -6.88498281e-03,\n",
       "        -3.45458724e-02,  -3.16057317e-02,   3.99220618e-04,\n",
       "        -1.40389474e-02,   4.28369306e-02,   6.07424155e-02,\n",
       "        -3.17661576e-02,  -3.87227573e-02,  -2.32099202e-02,\n",
       "        -1.15721757e-02,   4.98387702e-02,   7.29279546e-03,\n",
       "        -2.39843521e-02,   3.15418802e-02,  -1.25105185e-02,\n",
       "        -5.50798699e-02,   1.02968849e-01,  -4.63653216e-03,\n",
       "         4.26680036e-02,  -1.33410068e-02,   2.52621956e-02,\n",
       "         7.89969787e-02,  -6.26642182e-02,   3.93644124e-02,\n",
       "         2.15317309e-02,  -9.18426216e-02,  -3.31903920e-02,\n",
       "        -3.32187451e-02,   3.78724076e-02,  -1.11181393e-01,\n",
       "        -5.21998443e-02,   6.34790286e-02,  -4.24692892e-02,\n",
       "         1.70642808e-02,   6.33252487e-02,   3.05847935e-02,\n",
       "         3.93403284e-02,   1.41228199e-01,  -1.94571465e-02,\n",
       "         3.81996809e-03,  -6.42760545e-02,  -6.67585339e-03,\n",
       "        -1.29498105e-04,   6.54727221e-02,   7.92900547e-02,\n",
       "         9.75377560e-02,   1.05752852e-02,  -2.74947230e-02,\n",
       "         4.39139130e-03,   4.19173613e-02,   6.93197474e-02,\n",
       "         4.83259410e-02,  -6.22782744e-02,  -5.99406213e-02], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['woman']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно найти слова, похожие на заданное:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-11 19:30:26,492 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('child', 0.7217637300491333),\n",
       " ('girl', 0.7101114392280579),\n",
       " ('man', 0.6607055068016052),\n",
       " ('lady', 0.6375045776367188),\n",
       " ('lover', 0.6348167061805725),\n",
       " ('baby', 0.6139859557151794),\n",
       " ('herself', 0.6138506531715393),\n",
       " ('mother', 0.6019600033760071),\n",
       " ('person', 0.5906017422676086),\n",
       " ('husband', 0.589015007019043)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"woman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно также давать указания о том, какие слова считать похожими. Следующая команда возвращает первые 10 слов, похожие на woman и king, но не похожие на man:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.6211974620819092),\n",
       " ('empress', 0.5663551092147827),\n",
       " ('daughter', 0.5630096793174744),\n",
       " ('isabella', 0.554334819316864),\n",
       " ('husband', 0.553817093372345),\n",
       " ('princess', 0.5524237751960754),\n",
       " ('mary', 0.5424255728721619),\n",
       " ('elizabeth', 0.5415064692497253),\n",
       " ('throne', 0.5391876697540283),\n",
       " ('prince', 0.5263879895210266)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно также запросить меру сходства между заданными словами. Чтобы получить представление о том, как положение слов в пространстве погружения коррелирует с их семантикой, рассмотрим сл. пары слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71011161453468119"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"girl\", \"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58055631255012186"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"girl\", \"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29798874943153936"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"girl\", \"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47761547574044227"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"bus\", \"car\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, слова girl и woman больше похожи, чем girl и man, а car и bus больше похожи чем girl и car. Это хорошо согласуется с тем, как ранжировал бы схожесть человек.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение в GloVe\n",
    "\n",
    "Погружение слов GloBr (Global Vector) было предложено в работе \"GloVe: Global Vectors for Word Representation\" (C. Manning, J. Pennington, R. Socher). Авторы описывают GloVe как алгоритм обучения без учителя, цель которого - получение векторных представлений слов. Обучение производится на агрегированной глобальной статистике совместной встречаемости слов из корпуса, а получающиеся представления вскрывают интересные линейные структуры в векторном пространстве слов.\n",
    "\n",
    "GloVe отличаеися от word2vec тем, что word2vec прогностическая модель, тогда как GloVe основана на счетчиках. На первом шаге строится большая матрица совместной встречаемости пар (слово; контекст) в обучающем корпусе. Каждый элемент матрицы описывает, как часто слово, представленное данной строкой, встречается в контексте (обычно это последовательность слов), представленым данным столбцом.\n",
    "\n",
    "![](img/word2vec-pic3-glove.png)\n",
    "\n",
    "Алгоритм GloVe преобразует матрицу совместной встречаемости в пару матриц: (слово; признак) и (признак; контекст). Этот процесс называется **факторизацией матрицы** и выполняется итеративно посредством SGD.\n",
    "\n",
    "В форме уравнения записывается сл. образом: $R = P*Q \\approx R'$\n",
    "\n",
    "Здесь $R$ - исходная матрица совместной встречаемости. Сначала инициализируем $P$ и $Q$ случайными значениями и пытаемся воссоздать $R'$ путем их перемножения. Разница между реконструированной матрицей $R'$ и исходной $R$ покалывает, как надо изменить значения $P$ и $Q$, чтобы $R'$ стала ближе к $R$, т.е. ошибка реконструкции уменьшилась. Эта операция повторяется несколько раз, пока SGD не сойдется и ошибка реконструкции не станет ниже определенного порогового значени. Получившаяся в этот момент матрица (слово; признак) и является погружением в смысле GloVe. \n",
    "\n",
    "Прогностические модели на основе нейронных сетей типа word2vec и основанные на счетчиках модели GloVe преследуют одну и ту же цель. И те и другие строят векторное пространство так, что положение слова в нем зависит от соседних слов. Нейронная сеть начинает работу с отдельных примеров совместной встречаемости слов, а основанные на счетчиках модели - со статистики совместной встречаемости всех слов в корпусе. Недавно было опубликовано несколько работ, в которых демонстрируется корреляция между моделями обоих типов.\n",
    "\n",
    "В общем случае, GloVe отличается большей верностью, чем word2vec и быстрее обучается при использовании распараллеливания, поддержка её на Python пока не столь развита как word2vec. Пока единственным доступным инструментом является проект GloVe-Python (https://github.com/maciejkula/glove-python), предлагающий модельную реализацию GloVe на Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Использование предобученных погружений \n",
    "\n",
    "Вообще говоря, обучать модель word2vec или GloVe с нуля следует только тогда, когда имеется очень большой объем узкоспециализированных текстов. Чаще всего тем или иным способом используются предобученные погружения. Есть 3 основных способа включения погружений в собственную сеть:\n",
    "\n",
    "* обучение погружений с нуля;\n",
    "* настройка погружений на основе предобученных моделей GloVe\\word2vec;\n",
    "* поиск погружений в предобученных моделях GloVe/word2vec;\n",
    "\n",
    "В первом случае веса погружений инициализируются небольшими случайными значениями и обучаются методом обратного распространения ошибки. Этот способ уже рассмотрен на примере моделей skip-грамм и CBOW в Keras. Это режим по умолчанию при использовании слоя Embedding в собственной сети.\n",
    "\n",
    "Во втором случае из предобученной модели берется матрица весов и используется для инициализации весов слоя погружения. Сеть также обновляет веса методом обратного распространения ошибки , но модель сходится быстрее за счет хорошего выбора начальных весов.\n",
    "\n",
    "В третьем случае погружения слов ищутся в предобученной модели и входные данные преобразуются в векторные погружения. На преобразованных данных можно затем обучить любую модель (необязательно сеть глубокого обучения). Если предобученная модель обучалась на текстах из той же предметной области, что и целевая, то этот способ обычно дает прекрасные результаты и является самым дешевым.\n",
    "\n",
    "Для англоязычных текстов общего характера можно использовать модель word2vec от Google, обученную на 10 миллиардах слов из набора данных Google news. Размер словаря составляет примерно 3 миллиона слов, а размерность пространства погружения равна 300. Модель Google News (~1.5 Gb) можно скачать.\n",
    "\n",
    "С сайта GloVe можно скачать модель, обученную на 6 миллиардах лексем из англоязычной википедии и корпусе текстов, содержащем порядка миллиарда слов. Размер словаря составляет примерно 400 000 слов, для скачивания доступны модели с размерностью пространства 50,100,200 и 300. Размер модели составляет примерно 822 Mb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение погружений с нуля\n",
    "\n",
    "Обучим одномерную **сверточную нейронную сеть** классифицировать предложения по тональности. Прежде рассматривалось обучение двумерной сверточной сети для классификации изображений. В сверточных нейронных сетях используется пространственная структура изображения путем обеспечения локальной связности между нейронами соседних слоев.\n",
    "\n",
    "Для слов предложения характерна линейная структура, аналогичная пространстенной структуре в изображении. Традиционные (не на базе глубокого обучения) подходы к языковому моделированию подразумевают создание словесных n-грамм, улавливающих эту линейную структуру. ОДномерные сверточные нейронные сети делают нечто похожее, обучая сверточные фильтры, затрагивающие сразу несколько слов предложения и применяя к результатам max-пулинг, для создания вектора, представляющего важнейшие смысловые аспекты предложения.\n",
    "\n",
    "Существует еще один класс нейронных сетей, **рекуррентные нейронные сети**, специально предназначенные для обработки последовательных данных, в т.ч. текста, которые есть не что иное, как последовательность слов. Порядок обработки в РНС не такой как в сверточных. \n",
    "\n",
    "В нашей сети  входной текст преобразуется в последовательность индексов слов. Для грамматического разбора текста используется библиотека NLTK. Можно было бы применить регулярные выражения, но статистические модели предлагаемые NLTK, более пригодны для разбора текста.\n",
    "\n",
    "Последовательность индексов слов загружается в слой погружений заданного размера (в нашем случае число слов в самом длинном предложении). По умолчанию слой погружения инициализируется случайными значениями. Выход слоя погружения соединяется с одномерным светочным слоем, который сворачивает (в нашем примере0) словесные 3-граммы 256 различными способами (по сути дела применяет различные обученные линейные комбинации весов к погружениям слов). Эти признаки затем сводятся к единственному слову слоем глобального max-пулинга. Вектор длины 256 подается на вход плотного слоя, который выводит вектор длины 2. Функция активации sofrmax возвращает две вероятности: положительной и отрицательной эмоциональной тональности.\n",
    "\n",
    "![](img/word2vec-pic4.png)\n",
    "\n",
    "Рассмотрим реализацию в Keras. Фиксируем значение генератора случайных чисел для воспроизводимости результатов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Dropout, SpatialDropout1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее инициализируются константы. Мы будем классифицировать предложения из конкурса UMICH SI650 (https://www.kaggle.com/c/si650winter11#description), проводившийся на Kaggle.\n",
    "\n",
    "В этом наборе данных ~7000 редложений, положительно окрашенные снабжены меткой 1, отрицательно - меткой 0.\n",
    "\n",
    "Константа INPUT_FILE определяет путь к файлу размеченных предложений. \n",
    "\n",
    "Константа VOCAB_SIZE говорит, что мы будем рассматривать первые 5000 лексем текста. EMBED_SIZE - размер погружения, генерируемого слоем погружения нашей сети. NUM_FILTERS - число сверточных фильтров, обучаемых в сверточном слое, а NUM_WORDS - размер каждого фильтра, т.е. количество сворачиваемых за один раз слов.\n",
    "\n",
    "Константы BATCH_SIZE и NUM_EPOCH -- число загружаемых в одном пакете записей и количество проходов по всему набору данных в процессе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = \"./data/umich-sentiment-train.txt\"\n",
    "VOCAB_SIZE = 5000\n",
    "EMBED_SIZE = 100\n",
    "NUM_FILTERS = 256\n",
    "NUM_WORDS = 3\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем входные предложения и строим словарь из наиболее часто встречающихся слов. Этот словарь используется для преобразования входных предложений в список индексов слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = collections.Counter()\n",
    "fin = open(INPUT_FILE, \"r\", encoding='utf-8')\n",
    "maxlen = 0\n",
    "for line in fin:\n",
    "    _, sent = line.strip().split(\"\\t\")\n",
    "    words = [x.lower() for x in nltk.word_tokenize(sent)]\n",
    "    if len(words) > maxlen:\n",
    "        maxlen = len(words)\n",
    "    for word in words:\n",
    "        counter[word] += 1\n",
    "fin.close()\n",
    "\n",
    "word2index = collections.defaultdict(int)\n",
    "for wid, word in enumerate(counter.most_common(VOCAB_SIZE)):\n",
    "    word2index[word[0]] = wid + 1\n",
    "vocab_sz = len(word2index) + 1\n",
    "index2word = {v:k for k, v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждое предложение дополняется до длины maxlen (число слов в самом длинном предложении тренировочной выборки). Метки преобразуются в категориальный формат посредством служебной функции Keras. Последние два шага - стандартные операции обработки текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "fin = open(INPUT_FILE, \"r\", encoding='utf-8')\n",
    "for line in fin:\n",
    "    label, sent = line.strip().split(\"\\t\")\n",
    "    ys.append(int(label))\n",
    "    words = [x.lower() for x in nltk.word_tokenize(sent)]\n",
    "    wids = [word2index[word] for word in words]\n",
    "    xs.append(wids)\n",
    "fin.close()\n",
    "X = pad_sequences(xs, maxlen=maxlen)\n",
    "Y = np_utils.to_categorical(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные разбиваем на тренировочный и тестовый набор в соотношении 70:30. Теперь данные приведены к формату, пригодному для загрузки в сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4960, 42) (2126, 42) (4960, 2) (2126, 2)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.3, \n",
    "                                                random_state=42)\n",
    "print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим нейросеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_sz, EMBED_SIZE, input_length=maxlen))\n",
    "#model.add(SpatialDropout1D(Dropout(0.2)))\n",
    "model.add(Conv1D(filters=NUM_FILTERS, kernel_size=NUM_WORDS, activation=\"relu\"))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(2, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откомпилируем модель. Поскольку строится бинарный классификатор, то в качестве функции потерь выбирается categorial_crossentropy. В качестве оптимизатоа adam. Обучим модель на обучающем наборе, указав размер пакета 64 и число периодов 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4960 samples, validate on 2126 samples\n",
      "Epoch 1/20\n",
      "4960/4960 [==============================] - 12s - loss: 0.2681 - acc: 0.9032 - val_loss: 0.0343 - val_acc: 0.9887\n",
      "Epoch 2/20\n",
      "4960/4960 [==============================] - 11s - loss: 0.0164 - acc: 0.9952 - val_loss: 0.0204 - val_acc: 0.9929\n",
      "Epoch 3/20\n",
      "4960/4960 [==============================] - 11s - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0170 - val_acc: 0.9948\n",
      "Epoch 4/20\n",
      "4960/4960 [==============================] - 12s - loss: 0.0022 - acc: 0.9998 - val_loss: 0.0165 - val_acc: 0.9953\n",
      "Epoch 5/20\n",
      "4960/4960 [==============================] - 11s - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0164 - val_acc: 0.9948\n",
      "Epoch 6/20\n",
      "4960/4960 [==============================] - 12s - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0167 - val_acc: 0.9953\n",
      "Epoch 7/20\n",
      "4960/4960 [==============================] - 12s - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0165 - val_acc: 0.9958\n",
      "Epoch 8/20\n",
      "4960/4960 [==============================] - 12s - loss: 8.8605e-04 - acc: 0.9998 - val_loss: 0.0165 - val_acc: 0.9944\n",
      "Epoch 9/20\n",
      "4960/4960 [==============================] - 12s - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0165 - val_acc: 0.9948\n",
      "Epoch 10/20\n",
      "4960/4960 [==============================] - 12s - loss: 9.3500e-04 - acc: 0.9998 - val_loss: 0.0172 - val_acc: 0.9944\n",
      "Epoch 11/20\n",
      "4960/4960 [==============================] - 12s - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0166 - val_acc: 0.9953\n",
      "Epoch 12/20\n",
      "4960/4960 [==============================] - 12s - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0169 - val_acc: 0.9953\n",
      "Epoch 13/20\n",
      "4960/4960 [==============================] - 12s - loss: 7.3322e-04 - acc: 0.9998 - val_loss: 0.0173 - val_acc: 0.9948\n",
      "Epoch 14/20\n",
      "4960/4960 [==============================] - 12s - loss: 9.3823e-04 - acc: 0.9998 - val_loss: 0.0170 - val_acc: 0.9944\n",
      "Epoch 15/20\n",
      "4960/4960 [==============================] - 12s - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0168 - val_acc: 0.9944\n",
      "Epoch 16/20\n",
      "4960/4960 [==============================] - 12s - loss: 7.8648e-04 - acc: 0.9998 - val_loss: 0.0175 - val_acc: 0.9948\n",
      "Epoch 17/20\n",
      "4960/4960 [==============================] - 12s - loss: 8.4344e-04 - acc: 0.9998 - val_loss: 0.0170 - val_acc: 0.9944\n",
      "Epoch 18/20\n",
      "4960/4960 [==============================] - 12s - loss: 7.4665e-04 - acc: 0.9998 - val_loss: 0.0173 - val_acc: 0.9948\n",
      "Epoch 19/20\n",
      "4960/4960 [==============================] - 12s - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0172 - val_acc: 0.9953\n",
      "Epoch 20/20\n",
      "4960/4960 [==============================] - 12s - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0168 - val_acc: 0.9944\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=(Xtest, Ytest))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что на тестововм наборе верность составила 96.8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка погружений на баще предобученной модели word2vec\n",
    "\n",
    "Теперь мы будем использовать ту же сеть, что и прежде. Единственное существенное отличие - дополнтельный код для загрузки модели word2vec и построения матрицы весов для слоя погружения.\n",
    "\n",
    "Как всегда, начнем с импортирования и инициализации переменных. Также загрузис модель word2vec из gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from keras.layers.core import Dense, Dropout, SpatialDropout1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUM_EPOCH уменьшим с 20 на 10.\n",
    "\n",
    "Напомню, что инициализация весов значениями, взятыми из предобученной модели обычно ускоряет сходимость.\n",
    "\n",
    "Модель word2vec можно скачать здесь: https://github.com/mmihaltz/word2vec-GoogleNews-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = \"../data/umich-sentiment-train.txt\"\n",
    "WORD2VEC_MODEL = \"../data/GoogleNews-vectors-negative300.bin.gz\"\n",
    "VOCAB_SIZE = 5000\n",
    "EMBED_SIZE = 300\n",
    "NUM_FILTERS = 256\n",
    "NUM_WORDS = 3\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же как и ранее, из набора данных извлекаются слова и создается словарь частых термов, после чего набор данных разбирается для создания списков дополгненных слов. Метки преобразуются в категориальный формат. Данные разбиваются на тренировочную и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = collections.Counter()\n",
    "fin = open(INPUT_FILE, \"rb\")\n",
    "maxlen = 0\n",
    "for line in fin:\n",
    "    _, sent = line.strip().split(\"\\t\")\n",
    "    words = [x.lower() for x in nltk.word_tokenize(sent)]\n",
    "    if len(words) > maxlen:\n",
    "        maxlen = len(words)\n",
    "    for word in words:\n",
    "        counter[word] += 1\n",
    "fin.close()\n",
    "\n",
    "word2index = collections.defaultdict(int)\n",
    "for wid, word in enumerate(counter.most_common(VOCAB_SIZE)):\n",
    "    word2index[word[0]] = wid + 1\n",
    "vocab_sz = len(word2index) + 1\n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "    \n",
    "xs, ys = [], []\n",
    "fin = open(INPUT_FILE, \"r\", encoding='utf-8')\n",
    "for line in fin:\n",
    "    label, sent = line.strip().split(\"\\t\")\n",
    "    ys.append(int(label))\n",
    "    words = [x.lower() for x in nltk.word_tokenize(sent)]\n",
    "    wids = [word2index[word] for word in words]\n",
    "    xs.append(wids)\n",
    "fin.close()\n",
    "X = pad_sequences(xs, maxlen=maxlen)\n",
    "Y = np_utils.to_categorical(ys)\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.3, \n",
    "                                                random_state=42)\n",
    "print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим модель word2vec, предобученную на 10 миллиардах слов из новостей Google News со словарем на 3 миллиона слов. После загрузки ищем в модели векторы погружений для слов из словаря и записываем вектор погружений в нашу матрицу весов embedding_weights.\n",
    "\n",
    "Строки этой матрицы соответствуют словам из словаря, а столбцы - вектору погружений слова.\n",
    "\n",
    "Матрица embedding_weights имеет размер vocab_sz x EMBED_SIZE. Величина vocab_sz на единицу больше числа уникальных термов в словаре, дополнительная фиктивная лексема \\_UNK\\_ представляет собой отсутствующие в словаре слова.\n",
    "\n",
    "Вполне возможно, что в нашем словаре есть слова, отсутствующие в модели word2vec на базе GoogleNews. Для таких слов вектор погружений принимает значение по умолчанию - все нули.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load word2vec model\n",
    "word2vec = KeyedVectors.load_word2vec_format(WORD2VEC_MODEL, binary=True)\n",
    "embedding_weights = np.zeros((vocab_sz, EMBED_SIZE))\n",
    "for word, index in word2index.items():\n",
    "    try:\n",
    "        embedding_weights[index, :] = word2vec[word]\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличие от предыдущего примера при определении сети заключается в том, что веса слоя погружения хранящиеся в матрице embedding_weights, инициализированы в предшествующей части программы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_sz, EMBED_SIZE, input_length=maxlen,\n",
    "                    weights=[embedding_weights],\n",
    "                    trainable=True))\n",
    "model.add(SpatialDropout1D(Dropout(0.2)))\n",
    "model.add(Conv1D(filters=NUM_FILTERS, kernel_size=NUM_WORDS,\n",
    "                 activation=\"relu\"))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Компилируем модель, применяя категориальную перекрестную энтропию в качестве функции потерь и оптимизатор Adam, и обучим сеть при размере пакета 64 на протяжении 10 эпох.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=(Xtest, Ytest))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot loss function\n",
    "plt.subplot(211)\n",
    "plt.title(\"accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(Xtest, Ytest, verbose=1)\n",
    "print(\"Test score: {:.3f}, accuracy: {:.3f}\".format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После 10 периодов обучения модель показывает верность на тестовом наборе. Это лучше чем предыдущий пример, где достигнута верность 98.6 после 20 периодов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка погружений на базе предобученной модели GloVe\n",
    "\n",
    "Погружения на базе GloVe настраиваются примерно так же, как в случае модели word2vec. Отличается только код построения матрицы весов для слоя погружения. ЕГо мы и рассмотрим.\n",
    "\n",
    "Есть несколько видов предобученных моделей GloVe. Мы будем работать с той, что обучена на 6 миллиардах лексем и на корпусе текстов объемом порядка миллиарда слов из англоязычной википедии. Размер словаря модели составляет примерно 400 000 слов, имеются загружаемые файлы для размерности погружения 50, 100, 200 и 300. Возьмем файл размерности 300.\n",
    "\n",
    "Единственное, что нужно изменить в коде предыдущего примера - часть, где создается модель word2vec и инициализируется её матрица весов. А если бы мы взяли модель с размерностью отличной от 300, то нужно было бы еще изменить константу EMBED_SIZE.\n",
    "\n",
    "Векторы записаны в файле в текстовом формате через пробел, поэтому наша первая задача - прочитать их в словарь word2emb. Это делается аналогично разбору строки файла данных для модели word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GLOVE_MODEL = \"../data/glove.6B.300d.txt\"\n",
    "# load GloVe vectors\n",
    "word2emb = {}\n",
    "fglove = open(GLOVE_MODEL, \"rb\")\n",
    "for line in fglove:\n",
    "    cols = line.strip().split()\n",
    "    word = cols[0]\n",
    "    embedding = np.array(cols[1:], dtype=\"float32\")\n",
    "    word2emb[word] = embedding\n",
    "fglove.close()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После чего создается матрица весов погружения размера vocab_sz x EMBED_SIZE и заполняем её векторами из словаря word2emb. Векторы, которые соответствуют словам, имеющимся в словаре, но отсутствующим в модели GloVe, остаются нулевыми:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_weights = np.zeros((vocab_sz, EMBED_SIZE))\n",
    "for word, index in word2index.items():\n",
    "    try:\n",
    "        embedding_weights[index, :] = word2emb[word]\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полный код примера: https://github.com/PacktPublishing/Deep-Learning-with-Keras/blob/master/Chapter05/finetune_glove_embeddings.py\n",
    "\n",
    "Результат должен быть около 99.1%, что почти не уступает результатам, полученным после настройки весов модели word2vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск погружений\n",
    "\n",
    "Последняя стратегия - поиск погружений в предобученной сети. Для этого проще всего задать в наших примерах параметр trainable слоя погружения равным False.\n",
    "\n",
    "Тогда при обратном распространении ошибки не будут обновляться веса этого слоя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Embedding(vocab_sz, EMBED_SIZE, input_length = maxlen,\n",
    "                   weights = [embedding_weight], trainable=False))\n",
    "model.add(SpatialDropout1D(Dropout(0.2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поступив так в примерах для моделей word2vec и GloVe мы получим соответственно верность 98.7% и 98.9% после 10 периодов обучения.\n",
    "\n",
    "Однако, в общем случае предобученные погружения используются не так. Обычно производится предварительная обработка набора данных, цель которой - построить векторные представления слов путем поиска в какой-то предобученной модели, а затем воспользоваться этими данными для обучения другой модели. Вторая модель не будет содержать слоя погружения и вообще может не быть сетью глубокого обучения.\n",
    "\n",
    "В примере ниже описана плотная сеть, принимающая на входе вектор размера 100, представляющий предложение, и выводит 1, если предложение имеет положительную эмоциональную окраску, и 0 - если отрицательную.\n",
    "\n",
    "Мы по-прежнему используем набор данных UMICH S1650, содержащий примерно 7000 предложений.\n",
    "\n",
    "Как и прежде, большие куски кода повторяется, поэтому заострим внимание только на новых частях. \n",
    "\n",
    "Для создания 100-мерных векторов для каждого предложения потребуется модель GloVe размерности 100, которая хранится в файле glove.6B.100d.txt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "INPUT_FILE = \"../data/umich-sentiment-train.txt\"\n",
    "GLOVE_MODEL = \"../data/glove.6B.100d.txt\"\n",
    "VOCAB_SIZE = 5000\n",
    "EMBED_SIZE = 100\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее считываются предложения и создается таблица частот слов. Из этой таблицы отбирается 5000 самых частых лексем и строятся таблицы соответствия (отображающие слова на индексы и наоборот). Для лексем, отсутствующих в словаре, в таблице создается фиктивная лексема \\_UNK\\_. Пользуясь этими таблицами, мы преобразуем каждое предложение в последовательность идентификаторов слов, дополняя все предложения до одинаковой длины (равной числу слов в самом длинном предложении). Кроме того, метки преобразуются в категориальный формат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"reading data...\")\n",
    "counter = collections.Counter()\n",
    "fin = open(INPUT_FILE, \"rb\")\n",
    "maxlen = 0\n",
    "for line in fin:\n",
    "    _, sent = line.strip().split(\"\\t\")\n",
    "    words = [x.lower() for x in nltk.word_tokenize(sent)]\n",
    "    if len(words) > maxlen:\n",
    "        maxlen = len(words)\n",
    "    for word in words:\n",
    "        counter[word] += 1\n",
    "fin.close()\n",
    "\n",
    "print(\"creating vocabulary...\")\n",
    "word2index = collections.defaultdict(int)\n",
    "for wid, word in enumerate(counter.most_common(VOCAB_SIZE)):\n",
    "    word2index[word[0]] = wid + 1\n",
    "vocab_sz = len(word2index) + 1\n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "index2word[0] = \"_UNK_\"\n",
    "\n",
    "print(\"creating word sequences...\")\n",
    "ws, ys = [], []\n",
    "fin = open(INPUT_FILE, \"rb\")\n",
    "for line in fin:\n",
    "    label, sent = line.strip().split(\"\\t\")\n",
    "    ys.append(int(label))\n",
    "    words = [x.lower() for x in nltk.word_tokenize(sent)]\n",
    "    wids = [word2index[word] for word in words]\n",
    "    ws.append(wids)\n",
    "fin.close()\n",
    "W = pad_sequences(ws, maxlen=maxlen)\n",
    "Y = np_utils.to_categorical(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторы GloVe загружаются в словарь. Если бы мы хотели использовать модель word2vec, но нужно было бы лишь заменить этот блок вызовом функции Word2Vec.load_word2vec_format() из библиотеки gensim, а следующий - поиском в модели word2vec, а не в словаре word2emb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load GloVe vectors\n",
    "print(\"loading GloVe vectors...\")\n",
    "word2emb = collections.defaultdict(int)\n",
    "fglove = open(GLOVE_MODEL, \"rb\")\n",
    "for line in fglove:\n",
    "    cols = line.strip().split()\n",
    "    word = cols[0]\n",
    "    embedding = np.array(cols[1:], dtype=\"float32\")\n",
    "    word2emb[word] = embedding\n",
    "fglove.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующем фрагменте мы ищем слова каждого предложения в матрице идентификаторов слов W и записываем в матрицу E соответствующий вектор погружения. Сумма этих векторов образует вектор предложения, который записывается в матрицу X. На выходе получается матрица X размера num_records x EMBED_SIZE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"transferring embeddings...\")\n",
    "X = np.zeros((W.shape[0], EMBED_SIZE))\n",
    "for i in range(W.shape[0]):\n",
    "    E = np.zeros((EMBED_SIZE, maxlen))\n",
    "    words = [index2word[wid] for wid in W[i].tolist()]\n",
    "    for j in range(maxlen):\n",
    "        E[:, j] = word2emb[words[j]]\n",
    "    X[i, :] = np.sum(E, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы завершили предварительную обработку данных с использованием предобработанной модели и готовы применить их для обучения и оценки окончательной модели. Как обычно, разобьем данные на обучающий и тестовый набор в пропорции 70:30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.3, \n",
    "                                                random_state=42)\n",
    "print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для анализа эмоциональной окраски мы обучим простую плотную сеть. При компиляции задаем категориальную перекрестную энтропию в качестве функции потерь и оптимизатор Adam и обучаем сеть на векторах предложений, построенных на основе предобученных погружений. И наконец, оцениваем модели на тестовом наборе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=EMBED_SIZE, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=(Xtest, Ytest))\n",
    "# evaluate model\n",
    "score = model.evaluate(Xtest, Ytest, verbose=1)\n",
    "print(\"Test score: {:.3f}, accuracy: {:.3f}\".format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Плотная сеть с предварительной обработкой на 100-мерной модели GloVe дает верность 96.5% на тестовом наборе после обучения на протяжении 10 периодов. Сеть с предварительно обработкой на 300-мерной модели word2vec дает верность 98.5%.\n",
    "\n",
    "Код примера:\n",
    "GloVe: https://github.com/PacktPublishing/Deep-Learning-with-Keras/blob/master/Chapter05/transfer_glove_embeddings.py\n",
    "word2vec: https://github.com/PacktPublishing/Deep-Learning-with-Keras/blob/master/Chapter05/transfer_word2vec_embeddings.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дистрибутивные семантические модели для русского языка\n",
    "\n",
    "Основная сылка: http://rusvectores.org/ru/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распространенная проблема с word2vec - учет контекста и синонимы.\n",
    "\n",
    "Пример: москвич\n",
    "Заранее нельзя сказать о чем идет речь: \n",
    "* о человеке\n",
    "* о машине\n",
    "\n",
    "Есть последние достижения: параметрические модели word2vec, в которых удается передать скрытую контекстную переменную.\n",
    "\n",
    "Часто семантические взаимоотношения превращаются в геометрические представления в пространстве. \n",
    "Впрочем, это уже ставший классикой пример.\n",
    "\n",
    "king - man + woman = queen\n",
    "\n",
    "Для русского языка работает несколько хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вкратце рассмотрим Word2Vec в gensim. С загрузкой вы уже знакомы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-12 21:19:08,127 : INFO : loading projection weights from C:\\Users\\oleg-\\Downloads\\ruwikiruscorpora_0_300_20.bin\n",
      "2017-11-12 21:19:33,897 : INFO : loaded (392339, 300) matrix from C:\\Users\\oleg-\\Downloads\\ruwikiruscorpora_0_300_20.bin\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "\n",
    "word2vecRussian = KeyedVectors.load_word2vec_format('C:\\\\Users\\\\oleg-\\\\NLP\\\\word2vec\\\\ruwikiruscorpora_0_300_20.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поищем какое-нибудь слово:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'компьютер' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-b536b5ca3527>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword2vecRussian\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'компьютер'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\oleg-\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\oleg-\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    286\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'компьютер' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "word2vecRussian['компьютер']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что произошло?\n",
    "\n",
    "Если внимательно посмотреть документацию, то можно увидеть, что модель требует после целевого слова указать искомую часть речи. Нас интересует существительное, вместо \"компьютер\" укажем \"компьютер_NOUN\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -8.76659453e-02,  -3.63004208e-02,  -3.83421779e-02,\n",
       "        -4.05625552e-02,  -3.38673368e-02,   8.93075205e-03,\n",
       "        -1.31633142e-02,  -2.36338042e-02,   1.23950057e-02,\n",
       "         7.67279277e-03,  -2.74398439e-02,  -5.22567779e-02,\n",
       "        -1.26082405e-01,   2.46131569e-02,  -1.04117412e-02,\n",
       "         1.79650411e-02,  -7.55211152e-03,   7.14355260e-02,\n",
       "         7.54484981e-02,   6.07234165e-02,   3.95526998e-02,\n",
       "         7.51635358e-02,  -2.23440770e-02,   1.23516209e-01,\n",
       "         1.86109394e-02,  -1.40802832e-02,   3.46467569e-02,\n",
       "        -7.39386901e-02,  -1.37802223e-02,  -5.08520827e-02,\n",
       "        -1.38779858e-03,  -8.76183659e-02,   1.40914572e-02,\n",
       "         5.05875126e-02,   5.94712533e-02,  -3.09250336e-02,\n",
       "        -1.06489755e-01,  -3.17733325e-02,  -6.39012530e-02,\n",
       "        -3.81429940e-02,  -7.66539797e-02,  -9.77800786e-02,\n",
       "         6.00974597e-02,  -8.29136930e-03,  -3.61858197e-02,\n",
       "        -3.57093923e-02,  -1.06944581e-02,   7.26544559e-02,\n",
       "         4.11435738e-02,  -1.46084249e-01,  -2.76563279e-02,\n",
       "        -5.30271465e-03,   1.06135942e-02,  -4.20519821e-02,\n",
       "         1.35928858e-02,   2.72527337e-02,  -5.30740023e-02,\n",
       "        -4.55510989e-02,   1.72366411e-03,  -3.95642780e-02,\n",
       "        -1.24658011e-01,  -1.57004409e-02,  -4.81902272e-04,\n",
       "         4.50403728e-02,   5.78183234e-02,   1.47211617e-02,\n",
       "         7.38439560e-02,   8.55660215e-02,  -9.47219729e-02,\n",
       "        -1.61622502e-02,   2.77121421e-02,   3.63990404e-02,\n",
       "        -5.44753252e-03,   9.08168852e-02,  -1.97972022e-02,\n",
       "         1.23254240e-01,  -4.59447056e-02,  -1.44475490e-01,\n",
       "         9.38664451e-02,   8.93598050e-02,  -1.08165964e-02,\n",
       "         7.15899142e-03,   6.02155104e-02,   1.07342312e-02,\n",
       "         1.90951005e-02,   1.20554538e-02,  -3.93734612e-02,\n",
       "         8.43823608e-03,   2.52887770e-03,   7.42594600e-02,\n",
       "         4.73294929e-02,   1.00753762e-01,   9.39531326e-02,\n",
       "        -8.33612010e-02,   1.06980421e-01,   2.16306951e-02,\n",
       "        -5.07712252e-02,  -5.24314232e-02,   1.97021849e-02,\n",
       "        -1.01575935e-02,   2.39392482e-02,   1.04057878e-01,\n",
       "         2.62058582e-02,   9.32561886e-03,   1.01290621e-01,\n",
       "        -5.89241236e-02,  -5.95310889e-02,   6.71690097e-03,\n",
       "         9.44601372e-03,   1.88348256e-03,   3.35512199e-02,\n",
       "        -4.02113721e-02,  -3.06185838e-02,   5.50413802e-02,\n",
       "         4.95232753e-02,  -1.52478382e-01,  -1.04410656e-01,\n",
       "         9.80649889e-02,  -1.58969104e-01,   1.21227480e-01,\n",
       "        -5.61972968e-02,   1.13758802e-01,   4.44025882e-02,\n",
       "        -2.43162531e-02,   7.48489723e-02,   1.37711326e-02,\n",
       "        -2.44152006e-02,  -8.68788064e-02,   8.71910155e-03,\n",
       "        -9.02170315e-02,   2.12437231e-02,  -8.56868830e-03,\n",
       "         1.78120825e-02,  -4.78691272e-02,  -6.25687316e-02,\n",
       "         2.63293553e-02,  -3.68412584e-02,   2.15453934e-02,\n",
       "         6.41644150e-02,  -9.75525156e-02,  -6.25515776e-03,\n",
       "         3.29954699e-02,  -9.10382345e-02,   2.44019665e-02,\n",
       "        -8.22501630e-02,   3.33365463e-02,  -3.12733985e-02,\n",
       "        -1.27106803e-02,   1.15491606e-01,   2.67288871e-02,\n",
       "         1.24905799e-02,   6.94848523e-02,  -5.33490889e-02,\n",
       "        -6.07828237e-02,  -7.41813332e-02,   5.42570613e-02,\n",
       "        -1.90029088e-02,  -2.90559772e-02,   1.01397008e-01,\n",
       "        -1.82084441e-02,  -1.39367342e-01,  -6.33274391e-02,\n",
       "         7.84038305e-02,  -2.73638647e-02,  -5.57157993e-02,\n",
       "         4.77164909e-02,  -4.48491387e-02,  -7.67443925e-02,\n",
       "        -5.13825677e-02,  -6.89424276e-02,   1.85437761e-02,\n",
       "        -8.99478197e-02,   7.74423033e-02,  -5.19062914e-02,\n",
       "        -3.39002609e-02,   6.98711397e-03,   7.87972286e-02,\n",
       "        -4.51185815e-02,  -3.31093110e-02,  -7.76253045e-02,\n",
       "         6.85107410e-02,   3.70002948e-02,   5.85008450e-02,\n",
       "        -1.05058352e-04,  -5.43028638e-02,   4.38432507e-02,\n",
       "         8.04373703e-04,  -5.05810343e-02,   3.83420363e-02,\n",
       "        -8.26497525e-02,  -3.51518132e-02,  -1.25926062e-02,\n",
       "         5.14959618e-02,  -2.94746645e-02,   6.97191432e-02,\n",
       "         7.46099651e-02,   4.93666306e-02,  -9.35932174e-02,\n",
       "         8.94944742e-02,   2.41459329e-02,  -5.41586801e-02,\n",
       "        -1.09177329e-01,   2.31207330e-02,   1.08357236e-01,\n",
       "        -7.84245059e-02,   5.30642644e-02,   1.23569055e-03,\n",
       "        -6.39535040e-02,  -1.08952622e-03,  -6.07131459e-02,\n",
       "         1.64469033e-02,  -1.12445513e-02,  -5.34315929e-02,\n",
       "         1.21512786e-01,   2.91802287e-02,  -3.91216725e-02,\n",
       "        -5.73708862e-03,   2.19388362e-02,   6.00830764e-02,\n",
       "         4.13184054e-02,   2.60946695e-02,  -5.56203835e-02,\n",
       "         4.96001877e-02,  -2.54147723e-02,  -7.39996657e-02,\n",
       "         2.36843303e-02,   1.57568995e-02,  -1.19746383e-02,\n",
       "         8.33604559e-02,  -1.12052821e-02,   1.45850657e-02,\n",
       "         8.51506814e-02,  -5.54894358e-02,  -2.09626388e-02,\n",
       "        -2.03673411e-02,   1.54240634e-02,  -4.65708263e-02,\n",
       "        -3.16782817e-02,   1.09185860e-01,  -1.49140544e-02,\n",
       "        -6.28441572e-02,  -6.81457892e-02,  -4.15010452e-02,\n",
       "        -4.21320728e-04,   8.80697817e-02,   1.11813061e-02,\n",
       "         5.19906618e-02,  -1.38269169e-02,  -4.89565320e-02,\n",
       "        -1.69559121e-02,   7.84614589e-03,   3.64639387e-02,\n",
       "         7.35031301e-03,  -9.11810622e-02,   1.18093699e-01,\n",
       "        -1.86874513e-02,  -2.35112812e-02,   4.00785320e-02,\n",
       "         6.51778013e-04,  -3.18527333e-02,  -3.27573493e-02,\n",
       "         3.64217646e-02,  -7.31529295e-02,   1.47784948e-02,\n",
       "        -4.80444320e-02,   2.91921711e-03,   1.81924105e-02,\n",
       "        -5.70264347e-02,  -8.89884159e-02,  -3.11902035e-02,\n",
       "        -1.41850626e-02,  -5.62720197e-05,  -7.47802556e-02,\n",
       "        -6.62251562e-02,   1.25509417e-02,   8.28522258e-03,\n",
       "         5.05914986e-02,  -6.49324358e-02,  -1.55076636e-02,\n",
       "         3.29288542e-02,  -3.45757455e-02,  -4.58002798e-02,\n",
       "        -1.01563716e-02,  -1.58092454e-02,   4.15967293e-02,\n",
       "         1.43688656e-02,   3.77938189e-02,  -2.16936469e-02,\n",
       "        -7.16862753e-02,   8.29992518e-02,   5.56495041e-02,\n",
       "         1.96168032e-02,   7.19587132e-02,  -7.04791695e-02,\n",
       "        -5.15255630e-02,   8.20884407e-02,  -3.09662381e-03,\n",
       "        -4.55893986e-02,   8.59978944e-02,  -8.89510568e-03], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vecRussian['компьютер_NOUN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем также поиграть с арифметическими операциями в Word2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('королева_NOUN', 0.6030852198600769),\n",
       " ('монарх_NOUN', 0.5828707218170166),\n",
       " ('герцог_NOUN', 0.5751590132713318),\n",
       " ('принц_NOUN', 0.5383496284484863),\n",
       " ('правитель_NOUN', 0.5379163026809692),\n",
       " ('император_NOUN', 0.5316616892814636),\n",
       " ('карла_NOUN', 0.49433764815330505),\n",
       " ('царь_NOUN', 0.4933621883392334),\n",
       " ('принцесса_NOUN', 0.4891030788421631),\n",
       " ('франциск_NOUN', 0.4857705235481262)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vecRussian.most_similar(positive=['женщина_NOUN', 'король_NOUN'], negative=['мужчина_NOUN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И поискать похожие слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('караульная_NOUN', 0.534368634223938),\n",
       " ('дежурный_NOUN', 0.4848320186138153),\n",
       " ('комендатура_NOUN', 0.4704165458679199),\n",
       " ('внос_NOUN', 0.46642398834228516),\n",
       " ('караульный_ADJ', 0.45555976033210754),\n",
       " ('комендант_NOUN', 0.45342618227005005),\n",
       " ('патрульный::постовой_ADJ', 0.4422055780887604),\n",
       " ('гарнизонный_ADJ', 0.4412631094455719),\n",
       " ('оцепление_NOUN', 0.4387802481651306),\n",
       " ('оцеплять_VERB', 0.43705591559410095)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vecRussian.most_similar('комендантский_ADJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('полчаса_NOUN', 0.7180338501930237),\n",
       " ('сутки_NOUN', 0.7151405811309814),\n",
       " ('полдень_NOUN', 0.7013369202613831),\n",
       " ('полночь_NOUN', 0.6989853978157043),\n",
       " ('минута_NOUN', 0.6938785314559937),\n",
       " ('утро_NOUN', 0.6843180060386658),\n",
       " ('день_NOUN', 0.6639924645423889),\n",
       " ('часы_NOUN', 0.6618623733520508),\n",
       " ('неделя_NOUN', 0.6467037796974182),\n",
       " ('вечер_NOUN', 0.6267627477645874)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vecRussian.most_similar('час_NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('петербуржец_NOUN', 0.6915465593338013),\n",
       " ('ленинградец_NOUN', 0.5795994997024536),\n",
       " ('жигули_NOUN', 0.5448557734489441),\n",
       " ('питерец_NOUN', 0.5435524582862854),\n",
       " ('иномарка_NOUN', 0.5432823896408081),\n",
       " ('подмосковье_NOUN', 0.5405049324035645),\n",
       " ('москвичка_NOUN', 0.5247716307640076),\n",
       " ('азлк_NOUN', 0.5222724676132202),\n",
       " ('ростовчанин_NOUN', 0.5106713175773621),\n",
       " ('питерский_ADJ', 0.5061334371566772)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vecRussian.most_similar('москвич_NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('волжский_ADJ', 0.7309808135032654),\n",
       " ('ахтуба_NOUN', 0.6338326930999756),\n",
       " ('астрахань_NOUN', 0.601054847240448),\n",
       " ('кама_NOUN', 0.5870123505592346),\n",
       " ('воложка_NOUN', 0.5867355465888977),\n",
       " ('заволжье_NOUN', 0.5773836374282837),\n",
       " ('переволока_NOUN', 0.5755721926689148),\n",
       " ('селижаровка_NOUN', 0.5703670382499695),\n",
       " ('свияга_NOUN', 0.5689444541931152),\n",
       " ('москва-река_NOUN', 0.5621594786643982)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vecRussian.most_similar('волга_NOUN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список методов: https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText\n",
    "\n",
    "Последнее достижение в погружениях слов - это библиотека FastText: https://fasttext.cc/\n",
    "\n",
    "К ней доступны предобученные модели для **294 языков!** (Модели обучены на корпусе википедии).\n",
    "\n",
    "Использование моделей FastText:\n",
    "https://blog.manash.me/how-to-use-pre-trained-word-vectors-from-facebooks-fasttext-a71e6d55f27\n",
    "\n",
    "Предобученные модели: https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md\n",
    "\n",
    "## Ключевое различие между FastText и Word2Vec состоит в использовании n-грамм\n",
    "\n",
    "Word2Vec обучает векторы только на базе целых слов, найденных в тренировочном корпусе. \n",
    "\n",
    "FastText, с одной стороны, изучают векторы для n-грамм, которые он находит внутри каждого слова, а также для каждого целого слова. На каждом шаге обучения в FastText испоьзуется среднее целевого вектора слова и векторов его компонент (n-грамм). Затем проводится коррекция ошибки для обновления каждого вектора, который комбинировался с целеым вектором. Это привносит много дополнительных вычислений на фазе обучения. В каждой точке, необходимо суммировать и усреднять слова с их n-граммной компонентой.\n",
    "\n",
    "Компромиссом может выступать множество word-vectors, которые хранят встроенную информацию о подсловах (contain embedded sub-word information). Показано, что эти векторы имеют большую точность (с точки зрения различных метрик), чем векторы Word2Vec.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, word2vec обрабатывает каждое слово в корпусе как атомическую сущность и генерирует вектор для каждого слова. В этом смысле Word2Vec очень похож на GloVe - оба этих векторных представления обрабатывают слова как наименьшую единицу, на которой они обучаются.\n",
    "\n",
    "**FastText** (который прежде всего является расширением модели word2vec) обрабатывает каждое слово как композицию его символьных n-грамм. Поэтому вектор для слова порождается как сумма его символьных n-грамм. \n",
    "\n",
    "Например, вектор слова *apple* - сумма векторов n-грамм:\n",
    "\\_app, app, appl, apple, apple\\_, ppl, pple, ple, ple\\_, le\\_\n",
    "\n",
    "\n",
    "(Предполагаем, что гиперпараметр для наименьшей n-граммы равен трем, и максимальный равен 6). \n",
    "Это различие проявляется следующим образом:\n",
    "1. Лучшее порождение погружений  для редких слов (даже если слова достаточно редкие, их символьные n-граммы остаются общими с остальными словами - поэтому погружения слов остаются в пределах нормы).\n",
    "    * Это происходит потому, что в word2vec редкое слово (встречающееся, например, 10 раз) имеет меньшее число соседей, по сравнению со словом, которое встречается 100 раз - последний имеет больше соседей - контекстных слов, и поэтому используется чаще, что приводит к лучшим векторам слов. \n",
    "* Слова не из словаря - для них может быть сконструировано погружение слова на базе его символьных n-грамм, даже если слово вообще не появлялось в тренировочном корпусе! Ни Word2Vec, ни GloVe не могут обрабатывать слова, не появлявшиеся в тренировочном корпусе.\n",
    "* С точки зрения практики, выбор гиперпараметров, для генерации погружений слов FastText становится ключевым\n",
    "    * поскольку обучение производится на уровне символьных n-грамм, что занимает больше времени для генерации погружений, по сравнению с word2vec. Поэтому выбор гиперпараметров, контролирующих  минимальный и максимальный размер n-грамм имеет прямое отношение к этому времени.\n",
    "    * По мере роста объема корпуса, требования к оперативной памяти значительно возрастают -  число хэшируемых n-грамм будет постоянно расти. Поэтому, выбор гиперпараметра, контролирующего общее число hash buckets включая минимальный и максимальный размеры n-грамм будет напрямую влиять на это. Например, даже 256 Гб RAM будет недостаточно(!) для создания векторов лов для корпуса с ~50 миллионами уникальных слов с минимальным размером n-грамм 3, максимальным размером n-грамм 3 и минимальной встречаемостью слова 7. Минимальная встречаемость слова должна быть поднята до 15 для генерации векторов слов.\n",
    "* Использование символьных погружений (независимых символов, а не n-грамм) для различных задач показало рост производительности для этих задач по сравнению с использованием погружений слов, таких как word2vec или Glove.\n",
    "    * Хотя документы, сообщающие об этих улучшениях, как правило, используют символьные LSTM для генерации вложений, они не ссылаются на использование вложений FastText.\n",
    "    * Возможно, стоит рассмотреть погружения FastText для этих задач, поскольку генерация погружений FastText (несмотря на то, что она медленнее, чем word2vec), скорее всего, будет быстрее, по сравнению с LSTM (это просто догадка, нуждающаяся в проверке). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between word2vec and FastText:\n",
    "https://www.quora.com/What-is-the-main-difference-between-word2vec-and-fastText\n",
    "\n",
    "How does word2vec works?\n",
    "https://www.quora.com/How-does-word2vec-work-Can-someone-walk-through-a-specific-example/answer/Ajit-Rajasekharan\n",
    "\n",
    "Использование FastText как отдельного приложения:\n",
    "https://www.analyticsvidhya.com/blog/2017/07/word-representations-text-classification-using-fasttext-nlp-facebook/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
