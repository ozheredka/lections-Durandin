{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с нейронными сетями\n",
    "\n",
    "## Анатомия нейронной сети\n",
    "\n",
    "Обучение нейронной сети \"вращается\" вокруг следующих объектов:\n",
    "* Слои (layers), которые комбинируются в сеть (модель);\n",
    "* Входные данные (input data) и соответствующие ответы (targets);\n",
    "* Функцию потерь, которая определяет обратный сигнал, который используется для обучения;\n",
    "* Оптимизатор, определяющий как происходит обучение;\n",
    "\n",
    "Их взаимодействие можно визуализировать сл. образом: сеть, составленная из слоев, собранных вместе отображает входные данные (inpute data) в предсказания (predictions).\n",
    "\n",
    "Функция потерь (loss function) затем сравнивает эти предсказания с целевыми (targets), порождая стоимость потерь (loss value) являющуюся мерой насколько хорошо предсказания сети соответствуют истинным ответам. Оптимизатор использует стоимость потерь (loss value) чтобы обновить веса сети.\n",
    "\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/deep-learning-in-3-figures-3_alt.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример: бинарная классификация\n",
    "### IMDB dataset\n",
    "\n",
    "IMDB Dataset представляет собой множество из 50 000 обзоров с сайта IMDB. Они разделены: 25 000 обзоров на тренировочную и 25 000 обзоров на тестовую выборки, каждое множество содержит 50% негативных и 50% позитивных отзывов.\n",
    "\n",
    "Как и MNIST, набор данных IMDB предоставляется фреймворком Keras. Он уже предобработан: отзывы (последовательности слов) уже переведены в последовательности целых чисел, где каждое целое число соответствует своему слову в словаре.\n",
    "\n",
    "Ниже приведен пример загрузки этого набора данных (потребуется как минимум 80 Mb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17424384/17464789 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аргумент **num_words = 10000** означает, что мы будем использовать только 10 000 самых частовстречающихся слов в тренировочной выборке. Редкие слова будут отброшены. Это позволяет нам работать с вектором данных управляемого размера.\n",
    "\n",
    "Переменные **train_data** и **test_data** представляют собой списке обзоров, где каждый обзор является списком индексов слов (кодируют последовательности слов).\n",
    "**train_labels** и **test_labels** являются списками 0 и 1, где 0 соответствует *негативному отзыву* и 1 соответствует *позитивному отзыву*.\n",
    "\n",
    "Рассмотрим тренировочные данные и их метки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку мы ограничили себя 10 000 самых частовстречаемых слов, нет индексов слов, которые превосходят эту цифру. \n",
    "Проверим это:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот так мы можем быстро декондировать отзыв обратно в слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1605632/1641221 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# word_index - словарь, отображающий слова в целые числа\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# Мы \"обращаем\" его, отображая целые числа в слова\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# Теперь декодируем отзыв \n",
    "# Заметим, что индексы \"смещены\" на 3\n",
    "# 0,1,2 зарезервировано для padding, начала последовательности и \"неизвестного\" \n",
    "\n",
    "decoded_review  = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных\n",
    "\n",
    "Мы не можем сразу же отправить списки чисел в нейронную сеть. Мы должны преобразовать эти списки в тензорный формат.\n",
    "Есть два способа, чтобы сделать это:\n",
    "\n",
    "* Можно выровнять списки таким образом, чтобы они имели одинаковую длину и преобразовать их в целочисленный тензор размерности $(samples; word\\_indices)$, а затем использовать как первый слой в нашей нейросети как слой, способный обрабатывать такие целочисленные тензоры (т.н. Embedding слой - который будет рассмотрен в дальнейшем курсе лекций).\n",
    "* Можно произвести унитарное кодирование (one hot encode) списков чтобы преобразовать их в векторы нулей и единиц. Например, преобразование последовательности [3;5] в 10 000-мерный вектор, будет содержать все нули, за исключением 3 и 5 компонент, которые будут равны единице. Затем, мы можем использовать как первый слой в сети плотный слой (Dense layer), способный обрабатывать вещественные вектора данных.\n",
    "\n",
    "Рассмотрим (пока) последнее решение. Векторизуем данные самостоятельно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Преобразование последовательности целых чисел в бинарную матрицу\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension = 10000):\n",
    "    # Создание нулевой матрицы:\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        # Устанавливаем конкретные индексы в единицу\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "# Векторизация тренировочной выборки\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Векторищация тестовой выборки\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также следует векторизовать метки классов.\n",
    "Что достаточно просто:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, сейчас данные готовы к передачи в нейронную сеть\n",
    "\n",
    "## Построение нейронной сети\n",
    "\n",
    "Входные данные в нашем случае представляют собой вектора, а метки - скаляры (0 и 1): это достаточно простая конфигурация.\n",
    "\n",
    "Тип сети, который достаточно хорошо справляется с рассматриваемой проблемой (точнее, представлением) - просто стек плотных слоев (dense layers) с функцией активации relu:\n",
    "    Dense(16, activation='relu')\n",
    "   \n",
    "Аргумент 16 - это число \"скрытых единиц (hidden unit)\" в слое. Что такое hidden unit? Это размер в пространстве представления слоя (representation space of the layer).\n",
    "\n",
    "Каждый слой Dense с функцией активации relu выполняет следующую цепочку операций на тензорах:\n",
    "$$ output = relu(Wx + b)$$\n",
    "где $x$ - входной вектор.\n",
    "\n",
    "16 скрытых единиц будет означать, что матрица весов $W$ будет иметь пространство $(input\\_dimension, 16)$, т.е. скалярное произведение $W$ с входным вектором будет проецировать входные данные в 16 мерное пространство представления слоя (и затем мы можем добавить вектор смещения $b$ и применить операцию ReLU). \n",
    "\n",
    "Интуитивно, это можно понимать размерность пространства представления как \"как много свободы вы даете нейросети при изучении внутренних репрезентаций\".\n",
    "Чем больше скрытых единиц (многомерное пространство представления) позволяет нейронной сети изучить более сложные репрезентации, но это делает вашу сеть более дорогостоящей в вычислительном плане и может привести к нежелательным паттернам (например, переобучению).\n",
    "\n",
    "Необходимо сделать два ключевых архитектурных решения как \"складывать\" плотные слои:\n",
    "* Как много слоев использовать;\n",
    "* Как много \"скрытых единиц\" выбрать для каждого слоя.\n",
    "\n",
    "В последующем мы рассмотрим формальные принципы. Но сейчас остановимся на сл. архитектуре:\n",
    "* два промежуточных слоя с 16 скрытыми единицами;\n",
    "* третий слой, который выводит скалярное предсказание относительно тональности текущего текста (обзора);\n",
    "\n",
    "Промежуточгные слои будут использовать в качестве функции активации ReLU, а финальный уровень будет использовать сигмоидальную функцию активации, чтобы получить вероятность.\n",
    "\n",
    "Функция ReLU:\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/relu.png)\n",
    "\n",
    "Сигмоидальная функция:\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/sigmoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, наша нейронная сеть будет выглядеть сл. образом:\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/3_layer_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим эту нейросеть на Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ремарка: Что такое функции активации и почему они необходимы?\n",
    "\n",
    "Без использования функций активации (например, relu), плотный слой Dense будет содержать просто две линейные операции: скалярное произведение и сложение:\n",
    "$$ output = Wx + b$$\n",
    "\n",
    "Поэтому, слой может обучаться только линейным преобрразованиям (ффинным преобразованиям) входных данных, т.е. пространство гипотез слоя может быть лишь множеством всевозможных линейных преобразований входных данных в 16 мерном простраранстве. Такое пространство гипотез достаточно ограничено и мы не будем иметь каких-либо преимуществ от подобных репрезентаций (**почему???**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы расширить пространство гипотез, и получать преимущество оот глубоких прдставлений, необходима нелинейность, или функции активации. \n",
    "ReLU - одна из самых популярных функций активации в глубоком обучении, но существует также много других функций активации со странными именами: prelu, elu, и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, нам нужно выбрать функцию потерь и оптимизатор. Мы рассматриваем проблему бинарной классификации, а на выходе сети получаем вероятность, поэтому наилучшей функцией потерь является бинарная кросс-энтропия **binary_crossentropy**. \n",
    "\n",
    "Это не единственный выбор, вы можете выбрать хоть **mean_squared_error**. Но росс-энтропия **обычно** является наилучшим выбором, в тех случаях, когда мы имеем дело с моделями, выходом которых являются вероятности.\n",
    "\n",
    "Кросс-энтропия - это количественная мера из области теории информации, которая измеряет \"дистанцию\" между вероятностными распределениями, или , в нашем случае, между истинным распределением и нашими предсказаниями.\n",
    "\n",
    "Еще одним шагом при определении нашей модели является выбор оптимизатора. Мы сконфигурируем нашу модель с оптимизатором rmsprop и бинарной кросс-энтропией как функцию потерь.\n",
    "Также укажем, что мы хотим мониторить точность в ходе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы передали параметры как строки, что является возможным, поскольку rmsprop, banary_crossentropy и accuracy являются частью Keras.\n",
    "\n",
    "Иногда Вы можете захотеть сконфигурировать параметры оптимизатора, или передать произвольную функцию потерь, или произвольную метрику.\n",
    "Это может быть сделано передачей объекта класса optimizer как аргумента.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка подхода\n",
    "\n",
    "Чтобы мониторить точность модели в ходе обучения на данных которые никогда ранее не встречались, создается так называемая контрольная выборка (validation set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим нашу модель на 20 эпох (т.е. 20 итераций по всем объектам в тензорах X_train и y_train) в мини-пакетах (mini-batches) по 512 объектов.\n",
    "\n",
    "В то же время, будем мониторить потери и точность на 10 000 объектах контрольной выборки. Это делается посредством передачи контрольных данных с помощью аргумента validation_data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 24s - loss: 0.5136 - binary_accuracy: 0.7920 - val_loss: 0.4026 - val_binary_accuracy: 0.8628\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 4s - loss: 0.3132 - binary_accuracy: 0.9033 - val_loss: 0.3171 - val_binary_accuracy: 0.88290.\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.2294 - binary_accuracy: 0.9249 - val_loss: 0.2799 - val_binary_accuracy: 0.8917\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.1794 - binary_accuracy: 0.9428 - val_loss: 0.2734 - val_binary_accuracy: 0.8907\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.1481 - binary_accuracy: 0.9528 - val_loss: 0.2788 - val_binary_accuracy: 0.8889\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.1195 - binary_accuracy: 0.9630 - val_loss: 0.3257 - val_binary_accuracy: 0.8798\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.1021 - binary_accuracy: 0.9696 - val_loss: 0.3059 - val_binary_accuracy: 0.8848\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.0836 - binary_accuracy: 0.9761 - val_loss: 0.3379 - val_binary_accuracy: 0.8768\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.0719 - binary_accuracy: 0.9810 - val_loss: 0.3622 - val_binary_accuracy: 0.8790\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.0573 - binary_accuracy: 0.9863 - val_loss: 0.3744 - val_binary_accuracy: 0.8807\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.0481 - binary_accuracy: 0.9891 - val_loss: 0.4013 - val_binary_accuracy: 0.8781\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.0381 - binary_accuracy: 0.9921 - val_loss: 0.4423 - val_binary_accuracy: 0.8776\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.0293 - binary_accuracy: 0.9947 - val_loss: 0.4592 - val_binary_accuracy: 0.8759\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.0238 - binary_accuracy: 0.9959 - val_loss: 0.4834 - val_binary_accuracy: 0.8737\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.0194 - binary_accuracy: 0.9968 - val_loss: 0.5651 - val_binary_accuracy: 0.8688\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.0120 - binary_accuracy: 0.9993 - val_loss: 0.5551 - val_binary_accuracy: 0.8729\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.0122 - binary_accuracy: 0.9985 - val_loss: 0.5804 - val_binary_accuracy: 0.8718\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 4s - loss: 0.0094 - binary_accuracy: 0.9983 - val_loss: 0.6068 - val_binary_accuracy: 0.8683\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 4s - loss: 0.0082 - binary_accuracy: 0.9985 - val_loss: 0.6365 - val_binary_accuracy: 0.8669\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.0038 - binary_accuracy: 0.9999 - val_loss: 0.6698 - val_binary_accuracy: 0.8680\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По завершении каждой эпохи, происходит вычисление точности и потери на 10 000 объектов контрольной выборки.\n",
    "\n",
    "Следует также щаменить, что model.fit() возвращает объект класса History. Этот объект имеет поле history, являющееся словарем, содержащим данные обо всем, что происходит во время обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_binary_accuracy', 'loss', 'binary_accuracy'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Он содержит 4 поля: по одной метрике, которая мониторилась во время обучения и проверки.\n",
    "Используя Matplotlib можно построить графики потерь для тернировочной и контрольной выборки, как и верность.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJQUREcmnpCAiIvn+H45PIYVjqbLMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22689ef00b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRGL5/4xKq59rwtdOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22689fca320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['binary_accuracy']\n",
    "val_acc_values = history_dict['val_binary_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение потерь на тренировочной выборки уменьшается с каждой эпохов, в то время как точность на тренировочной выборке возрастает. \n",
    "Это то, что мы ожидаем от градиентного спуска - количественные показатели, которые должны минимизироваться с каждой итерацией. Но это не так для функции потерь в контрольной выборке! Они достигают пика гд-то в 4 эпоху. \n",
    "\n",
    "Это как раз тот случай, о котором мы говорили ранее: модель все лучше описывает данные на тренировочной выборке и в результате начинает излишне адоптироваться к ней, мешая, таким образом, генерализации.\n",
    "\n",
    "В нашем простом случае, чтобы предотвратить переобучение достаточно было бы остановить обучение после 3 эпох. Разумеется, есть и более сложные методы борьбы с переобучением.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 14s - loss: 0.4717 - acc: 0.8106    \n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 4s - loss: 0.2651 - acc: 0.9080     \n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 4s - loss: 0.2023 - acc: 0.9277     \n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 4s - loss: 0.1687 - acc: 0.9402     \n",
      "24992/25000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2911977368068695, 0.88500000000000001]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, наш наивный подход достиг точности 88%. Современные подходы способны приблизиться к 95% точности.\n",
    "\n",
    "## Использование обученной модели для генерации предсказаний на новых данных\n",
    "\n",
    "После обучения нейронной сети, её можно использовать на практике. Можно породить вероятность позитивной тональности с использованием метода predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.923392  ],\n",
       "       [ 0.83488482],\n",
       "       [ 0.99946672],\n",
       "       ..., \n",
       "       [ 0.44186568],\n",
       "       [ 0.00358829],\n",
       "       [ 0.80997139]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить, нейронная сеть очень уверена для одних ответов (вероятность более 0.99, или менее 0.01) но менее уверена для других."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Упражнения:**\n",
    "* Использовались 2 скрытых уровня сети. Попробуйте использовать 1 или 3 скрытых уровня нейронной сети и посмотрите как это влияет на точность контрольной и тестовой выборки;\n",
    "* Попробуйте использовать слои с большим числом скрытых единиц (нейронов) в слое: 32, 64 и т.д.\n",
    "* Попробуйте использовать mse в качестве функции потерь (вместо binary_crossentropy); \n",
    "* Попробуйте использовать в качестве функции активации tanh (вместо relu);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример: многоклассовая классификация (классификация новостей)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы рассмотрели, как классифицировать данные, с двумя взаимоисключающими классами с использованием плотной нейронной сети.\n",
    "\n",
    "Но что происходит когда классов больше двух?\n",
    "\n",
    "Рассмотрим другой case: построим нейронную сеть, для классификации новостей из Reuters по 46 разным взаимоисключающим категориям.\n",
    "Эта проблема называется многоклассовой классификацией (multiclass classification).\n",
    "\n",
    "### Reuters dataset\n",
    "\n",
    "Будем работать с набором данных Reuters, который содержит множество коротких новостей и их темы, опубликованые Reuters в 1986 году. Это достаточно простой, широко распространенный набор для классификации.\n",
    "Есть 46 тем, некоторые темы более репрезентативны, чем другие, но каждая тема имеет как минимум 10 обхектов в тренировочной выборке.\n",
    "\n",
    "Как и IMDB и MNIST, Reuters поставляется как часть Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2023424/2110848 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и с IMDB ограничим себя 10 000 наиболее частовстречающимися словами.\n",
    "\n",
    "Посмотрим на объем выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим декодер, чтобы мы могли преобразовывать цифровую репрезентацию отзыва в обычные слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
      "540672/550378 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# Note that our indices were offset by 3\n",
    "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метки, ассоциированные с примерами пронумерованы числами от 0 до 45: индекс темы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных\n",
    "\n",
    "Мы можем векторизовать данные таким же образом, как и ранее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для векторизации меток есть две возможности:\n",
    "* Использовать список меток как целочисленный тензор;\n",
    "* Использовать унитарное кодирование;\n",
    "\n",
    "Унитарное кодирование (one-hot encoding) - ширико используемый формат для категориальных данных, также называемый категориальным кодированием.\n",
    "\n",
    "В нашем случае, унитарное кодирование меток состоит в том, что каждой метке ставится в соответствие вектор, содержащий единицу в размерности, равной индексу метки, а в остальных компонентах - нули.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "# Our vectorized training labels\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "# Our vectorized test labels\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следует, однако, заметить, что Keras предоставляет возможность преобразования в категориальную форму встроенной функцией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение нейронной сети\n",
    "\n",
    "Задача классификации тематики похожа на задачу классификации отзывов: в обоих случаях мы пытаемся классифицировать короткие сниппеты текста.\n",
    "\n",
    "Фундаментальным отличием является то, что число классов возрастает от 2 до 46, т.е. размерность выходного пространства значительно вырастает.\n",
    "\n",
    "При \"стекинге \" плотных слоев (Dense layer) нейронной сети каждый слой может иметь доступ только к информации, представленной в результатах предыдущего слоя.\n",
    "\n",
    "Если один слой \"отбрасывает\" некоторую важную информацию, релевантную задаче классификации, эта информация уже не может быть восстановлена на последующих уровнях: каждый слой может иметь потенциальные **\"information bottleneck\"**. \n",
    "\n",
    "В предыдущем примере мы использовали 16 мерные промежуточные слои, но пространство размерности 16 может быть слишком ограниченым, чтобы научиться отличать 46 различных классов! Такие малые слои могут выступать как узкие места, перманентно отбрасывая релевантную информацию.\n",
    "\n",
    "По этим причинам будем использовать слои с 64 нейронами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно также отметить еще две вещи относительно текущей архитектуры:\n",
    "\n",
    "* Мы завершаем нейронную сеть с плотным слоем (Dense layer) размером 46. Это означает, что для каждого входого объекта, сеть будет порождать вектор, размерности 46. Каждый элемент в таком векторе (т.е. каждая размерность) будет кодировать разный выходной класс.\n",
    "* Последний уровень использует softmax в качестве функции активации. Это означает, что сеть будет порождать веротяностное распределение над 46 различными выходными классами, т.е. для каждого входого объекта, сеть будет порождать выходной вектор, размерности 46.\n",
    "\n",
    "Исползуемая функция потерь в этом случае: категориальная кросс-энтропия (categorial_crossentropy). Она измеряет дистанцию между двумя вероятностными распределениями: в нашем случае, разность между вероятностным распределением, порождаемым нашей сетью и истинным распределением меток.\n",
    "\n",
    "Минимизацией расстояние между этими двумя распределением мы обучаем нашу нейронную сеть порождать метки максимально близкие к истинным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Валидация подхода\n",
    "\n",
    "Разобьем тренировочную выборку, так чтобы использовать контрольную выборку.\n",
    "\n",
    "После чего бучим нашу сеть на 20 эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 4s - loss: 2.5306 - acc: 0.4962 - val_loss: 1.7180 - val_acc: 0.6120\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 2s - loss: 1.4430 - acc: 0.6878 - val_loss: 1.3435 - val_acc: 0.7060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 2s - loss: 1.0929 - acc: 0.7661 - val_loss: 1.1704 - val_acc: 0.7430\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.8682 - acc: 0.8166 - val_loss: 1.0788 - val_acc: 0.7600\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.7020 - acc: 0.8483 - val_loss: 0.9844 - val_acc: 0.7830\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.5666 - acc: 0.8796 - val_loss: 0.9401 - val_acc: 0.8030\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.4592 - acc: 0.9039 - val_loss: 0.9090 - val_acc: 0.8010\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.3704 - acc: 0.9226 - val_loss: 0.9359 - val_acc: 0.7890\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.3036 - acc: 0.9308 - val_loss: 0.8912 - val_acc: 0.8070\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.2539 - acc: 0.9412 - val_loss: 0.9059 - val_acc: 0.8110\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.2185 - acc: 0.9471 - val_loss: 0.9152 - val_acc: 0.8120\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.1872 - acc: 0.9511 - val_loss: 0.9045 - val_acc: 0.8150\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.1696 - acc: 0.9523 - val_loss: 0.9338 - val_acc: 0.8090\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.1531 - acc: 0.9554 - val_loss: 0.9644 - val_acc: 0.8090\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.1387 - acc: 0.9555 - val_loss: 0.9697 - val_acc: 0.8120\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.1310 - acc: 0.9562 - val_loss: 1.0280 - val_acc: 0.8040\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.1214 - acc: 0.9577 - val_loss: 1.0307 - val_acc: 0.7950\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.1193 - acc: 0.9582 - val_loss: 1.0454 - val_acc: 0.8080\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.1136 - acc: 0.9595 - val_loss: 1.1013 - val_acc: 0.7950\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 2s - loss: 0.1104 - acc: 0.9595 - val_loss: 1.0710 - val_acc: 0.8020\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график функции потерь и верности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhIipKCiIikKCmIiEjK/wen606ZMfrK/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x226f1ac8ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2268a0e25c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже, что сеть начинает переобучаться через 9 эпох. Обучим сетку с нуля, за девять эпох и оценим результаты на тестовой выборке.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 3s - loss: 2.5401 - acc: 0.5226 - val_loss: 1.6792 - val_acc: 0.6540\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 2s - loss: 1.3785 - acc: 0.7096 - val_loss: 1.2825 - val_acc: 0.7210\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 2s - loss: 1.0207 - acc: 0.7781 - val_loss: 1.1321 - val_acc: 0.7550\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 2s - loss: 0.8003 - acc: 0.8257 - val_loss: 1.0532 - val_acc: 0.7580\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 2s - loss: 0.6392 - acc: 0.8629 - val_loss: 0.9753 - val_acc: 0.7950\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 2s - loss: 0.5112 - acc: 0.8930 - val_loss: 0.9097 - val_acc: 0.8130\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 2s - loss: 0.4115 - acc: 0.9141 - val_loss: 0.8913 - val_acc: 0.8240\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 2s - loss: 0.3357 - acc: 0.9283 - val_loss: 0.8725 - val_acc: 0.8280\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 2s - loss: 0.2787 - acc: 0.9371 - val_loss: 0.9345 - val_acc: 0.8010\n",
      "2208/2246 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0225298037405854, 0.77738201251968353]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наш подход достигает точности ~78%. В случае сбалансированной задачи бинарной классификации, точность, достигаемая случайным классификатором, составит 50%.\n",
    "В нашем случае она ближе к 19%, поэтому наши результаты кажутся достаточно хорошими, по сранвнению со случайной базой.\n",
    "\n",
    "### Генерация предсказаний на новых данных\n",
    "\n",
    "Мы можем убедиться, что метод predict нашей модели возвращает вероятностное распределение над всеми 46 темами.\n",
    "Сгенерируем предсказания для всех тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый элемент в predictions представляет собой вектор размерности 46:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сумма его коэффициентов равна единице:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Еще один способ обработки меток и потери\n",
    "\n",
    "Ранее было упомянуто, что еще один способ кодирования меток может заключаться в их преобразовании в целочисленный тензор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следует, однако, отметить, что это приведет к изменению в выборе функции потерь. Предыдущая функция потерь, категориальная кросс-энтропия (categorial_crossentropy) ожидает, что метки будут соответствовать категориальному кодирования. С целочисленными метками следует использовать **sparse_categorial_crossentropy**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта \"новая\" функция потерь с математической точки зрения остается той же самой, что и categorial_crossentropy, однако она будет иметь другой интерфейс.\n",
    "\n",
    "### О важности наличия достаточно больших промежуточных слоев\n",
    "\n",
    "Ранее было упомянуто, что поскольку финальный выход 46 мерный, то нам следует избегать промежуточных слоев с менее чем 46 скрытыми нейронами. \n",
    "\n",
    "Попытаемся увидеть, что произойдет, когда мы введем information bottleneck - промежуточные слои значительно меньшие чем с 46 скрытыми нейронами (например, размерности 4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 4s - loss: 3.1689 - acc: 0.2447 - val_loss: 2.6152 - val_acc: 0.2720\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 3s - loss: 2.0600 - acc: 0.5428 - val_loss: 1.7015 - val_acc: 0.5870\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 3s - loss: 1.5001 - acc: 0.6253 - val_loss: 1.5088 - val_acc: 0.6440\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 3s - loss: 1.2854 - acc: 0.6917 - val_loss: 1.4107 - val_acc: 0.6760\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 3s - loss: 1.1434 - acc: 0.7155 - val_loss: 1.3671 - val_acc: 0.6820\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 3s - loss: 1.0390 - acc: 0.7310 - val_loss: 1.3435 - val_acc: 0.6970\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.9566 - acc: 0.7419 - val_loss: 1.3399 - val_acc: 0.69900.7\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.8866 - acc: 0.7534 - val_loss: 1.3338 - val_acc: 0.7080\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.8209 - acc: 0.7737 - val_loss: 1.3535 - val_acc: 0.7170\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.7587 - acc: 0.7929 - val_loss: 1.3693 - val_acc: 0.7170\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.7062 - acc: 0.8072 - val_loss: 1.4011 - val_acc: 0.7150\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.6613 - acc: 0.8188 - val_loss: 1.3996 - val_acc: 0.7220\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.6195 - acc: 0.8312 - val_loss: 1.4529 - val_acc: 0.7110\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.5823 - acc: 0.8359 - val_loss: 1.4718 - val_acc: 0.7140 - acc: \n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.5497 - acc: 0.8439 - val_loss: 1.5114 - val_acc: 0.7160\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.5200 - acc: 0.8530 - val_loss: 1.5548 - val_acc: 0.7170\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.4934 - acc: 0.8642 - val_loss: 1.5793 - val_acc: 0.7190\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.4695 - acc: 0.8775 - val_loss: 1.6320 - val_acc: 0.7190TA: 1s - loss:\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.4449 - acc: 0.8837 - val_loss: 1.6747 - val_acc: 0.7100\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 3s - loss: 0.4275 - acc: 0.8891 - val_loss: 1.7515 - val_acc: 0.7150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2268a538748>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сеть показывает на контрольной выборке верность равную ~71%. Т.е. абсолютное падение на 9%. \n",
    "\n",
    "Причина этого падения, преимущественно в том, что сейчас мы пытаемся \"сжать\" много информации в промежуточном слое, размерность которого слишком мала. \n",
    "\n",
    "Сеть может втиснуть большую часть необходимой информации в это представление, но далеко не всю.\n",
    "\n",
    "**Упражнения**\n",
    "* Попробуйте слои с большим и меньшим числом нейронов: 32, 128 и т.д.\n",
    "* Попробуйте 1 скрытый слой, три скрытых слоя и т.д.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение задачи регрессии с помощью нейронных сетей\n",
    "\n",
    "В предыдущих примерах рассматривались задачи классификации. Однако, нейронные сети способны решать не только задачи классификации, но и задачи регрессии.\n",
    "\n",
    "### Boston Housing Price dataset\n",
    "\n",
    "Попытаемся предсказать медианную цену домов в Бостоне в середине 1970-х годов, учитывая некоторые данные о районе в то время, такие как уровень преступности, ставка налога на собственность и т.д.\n",
    "\n",
    "Набор данных Boston Housing Price имеет сравнительно немного объектов: всего 506, при разбиении: 404 объекта в тренировочной выборке и 102 в тестовой выборке. \n",
    "\n",
    "И каждый атрибут во входных данных имеет разную шкалу. Например, некоторые значения могут быть доли, принимающие значения между 0 и 1, другие могут принимать значения между 1 и 12, а другие между 0 и 100...\n",
    "\n",
    "Итак, загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 1s     \n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных имеет 13 атрибутов:\n",
    "\n",
    "1. Per capita crime rate.\n",
    "* Proportion of residential land zoned for lots over 25,000 square feet.\n",
    "* Proportion of non-retail business acres per town.\n",
    "* Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "* Nitric oxides concentration (parts per 10 million).\n",
    "* Average number of rooms per dwelling.\n",
    "* Proportion of owner-occupied units built prior to 1940.\n",
    "* Weighted distances to five Boston employment centres.\n",
    "* Index of accessibility to radial highways.\n",
    "* Full-value property-tax rate per $10,000.\n",
    "* Pupil-teacher ratio by town.\n",
    "* 1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town.\n",
    "* % lower status of the population.\n",
    "\n",
    "Целевые значения представляют собой медианные значения цены (в тыс. долларов).\n",
    "Цены обычно распределены между 10 000 и 50 000 долларов (помните, что 1970-е годы и без поправок на инфляцию)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.2,  42.3,  50. ,  21.1,  17.7,  18.5,  11.3,  15.6,  15.6,\n",
       "        14.4,  12.1,  17.9,  23.1,  19.9,  15.7,   8.8,  50. ,  22.5,\n",
       "        24.1,  27.5,  10.9,  30.8,  32.9,  24. ,  18.5,  13.3,  22.9,\n",
       "        34.7,  16.6,  17.5,  22.3,  16.1,  14.9,  23.1,  34.9,  25. ,\n",
       "        13.9,  13.1,  20.4,  20. ,  15.2,  24.7,  22.2,  16.7,  12.7,\n",
       "        15.6,  18.4,  21. ,  30.1,  15.1,  18.7,   9.6,  31.5,  24.8,\n",
       "        19.1,  22. ,  14.5,  11. ,  32. ,  29.4,  20.3,  24.4,  14.6,\n",
       "        19.5,  14.1,  14.3,  15.6,  10.5,   6.3,  19.3,  19.3,  13.4,\n",
       "        36.4,  17.8,  13.5,  16.5,   8.3,  14.3,  16. ,  13.4,  28.6,\n",
       "        43.5,  20.2,  22. ,  23. ,  20.7,  12.5,  48.5,  14.6,  13.4,\n",
       "        23.7,  50. ,  21.7,  39.8,  38.7,  22.2,  34.9,  22.5,  31.1,\n",
       "        28.7,  46. ,  41.7,  21. ,  26.6,  15. ,  24.4,  13.3,  21.2,\n",
       "        11.7,  21.7,  19.4,  50. ,  22.8,  19.7,  24.7,  36.2,  14.2,\n",
       "        18.9,  18.3,  20.6,  24.6,  18.2,   8.7,  44. ,  10.4,  13.2,\n",
       "        21.2,  37. ,  30.7,  22.9,  20. ,  19.3,  31.7,  32. ,  23.1,\n",
       "        18.8,  10.9,  50. ,  19.6,   5. ,  14.4,  19.8,  13.8,  19.6,\n",
       "        23.9,  24.5,  25. ,  19.9,  17.2,  24.6,  13.5,  26.6,  21.4,\n",
       "        11.9,  22.6,  19.6,   8.5,  23.7,  23.1,  22.4,  20.5,  23.6,\n",
       "        18.4,  35.2,  23.1,  27.9,  20.6,  23.7,  28. ,  13.6,  27.1,\n",
       "        23.6,  20.6,  18.2,  21.7,  17.1,   8.4,  25.3,  13.8,  22.2,\n",
       "        18.4,  20.7,  31.6,  30.5,  20.3,   8.8,  19.2,  19.4,  23.1,\n",
       "        23. ,  14.8,  48.8,  22.6,  33.4,  21.1,  13.6,  32.2,  13.1,\n",
       "        23.4,  18.9,  23.9,  11.8,  23.3,  22.8,  19.6,  16.7,  13.4,\n",
       "        22.2,  20.4,  21.8,  26.4,  14.9,  24.1,  23.8,  12.3,  29.1,\n",
       "        21. ,  19.5,  23.3,  23.8,  17.8,  11.5,  21.7,  19.9,  25. ,\n",
       "        33.4,  28.5,  21.4,  24.3,  27.5,  33.1,  16.2,  23.3,  48.3,\n",
       "        22.9,  22.8,  13.1,  12.7,  22.6,  15. ,  15.3,  10.5,  24. ,\n",
       "        18.5,  21.7,  19.5,  33.2,  23.2,   5. ,  19.1,  12.7,  22.3,\n",
       "        10.2,  13.9,  16.3,  17. ,  20.1,  29.9,  17.2,  37.3,  45.4,\n",
       "        17.8,  23.2,  29. ,  22. ,  18. ,  17.4,  34.6,  20.1,  25. ,\n",
       "        15.6,  24.8,  28.2,  21.2,  21.4,  23.8,  31. ,  26.2,  17.4,\n",
       "        37.9,  17.5,  20. ,   8.3,  23.9,   8.4,  13.8,   7.2,  11.7,\n",
       "        17.1,  21.6,  50. ,  16.1,  20.4,  20.6,  21.4,  20.6,  36.5,\n",
       "         8.5,  24.8,  10.8,  21.9,  17.3,  18.9,  36.2,  14.9,  18.2,\n",
       "        33.3,  21.8,  19.7,  31.6,  24.8,  19.4,  22.8,   7.5,  44.8,\n",
       "        16.8,  18.7,  50. ,  50. ,  19.5,  20.1,  50. ,  17.2,  20.8,\n",
       "        19.3,  41.3,  20.4,  20.5,  13.8,  16.5,  23.9,  20.6,  31.5,\n",
       "        23.3,  16.8,  14. ,  33.8,  36.1,  12.8,  18.3,  18.7,  19.1,\n",
       "        29. ,  30.1,  50. ,  50. ,  22. ,  11.9,  37.6,  50. ,  22.7,\n",
       "        20.8,  23.5,  27.9,  50. ,  19.3,  23.9,  22.6,  15.2,  21.7,\n",
       "        19.2,  43.8,  20.3,  33.2,  19.9,  22.5,  32.7,  22. ,  17.1,\n",
       "        19. ,  15. ,  16.1,  25.1,  23.7,  28.7,  37.2,  22.6,  16.4,\n",
       "        25. ,  29.8,  22.1,  17.4,  18.1,  30.3,  17.5,  24.7,  12.6,\n",
       "        26.5,  28.7,  13.3,  10.4,  24.4,  23. ,  20. ,  17.8,   7. ,\n",
       "        11.8,  24.4,  13.8,  19.4,  25.2,  19.4,  19.4,  29.1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных\n",
    "\n",
    "\"Скормить\" нейросети значения, которые имеют разные диапазоны. Нейронная сеть может автоматически адаптироваться к таким гетерогенным данным, но это определенно делает обучение намного сложнее.\n",
    "\n",
    "Широкораспространенной практикой при работе с такими данными - выполнять нормализацию по атрибутам (feature-wise normalization): для каждой атрибуты входных данных (столбец в матрице входных данных), мы вычитаем среднее (матожидание) и делим на стандартное отклонение, тоесть атрибуты будут центрированы около 0 и измеряется стандартным отклонением.\n",
    "Нормализация данных в NumPy делается очень просто:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что величины, которые мы используем для нормализации тестовых данных вычислялись с использованием данных обучения.\n",
    "\n",
    "Мы никогда не должны использовать в рабочем процессе какие-либо количественные метрики, вычисленные на тренировочных данных, даже для таких простых вещей как нормализация данных.\n",
    "\n",
    "### Построение нейронной сети\n",
    "\n",
    "Поскольку нам доступно небольшое количество объектов, мы будем использовать достаточно малую нейронную сеть с двумя скрытыми уровнями, по 64 скрытых нейрона каждый.\n",
    "\n",
    "В целом, чем меньше у вас данных, тем хуже будет переобучение, а использование небольшой сети - это один из способов смягчения переобучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    # Because we will need to instantiate\n",
    "    # the same model multiple time,\n",
    "    # we use a function to construct it.\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейронная сеть завершается слоем с одним нейроном без активации (т.е. по факту - линейным слоем). Это достаточно типичная установка для скалярной регрессии. Применение функции активации будет ограничивать диапазон выходных значений, например если мы применим сигмоидальную функцию активации к последнему слою, сеть будет обучаться предсказывать значения между 0 и 1.\n",
    "\n",
    "Поскольку последний уровень линейные, сеть свободна в выборе диапазона предсказываемых значений.\n",
    "\n",
    "Следует также заметить, что мы компилируем сеть с функцией потерь mse - mean squared error (среднеквадратичная ошибка), - квадрат разности между предсказаниями и целевыми значениями. MSE является широко распространенной функцией потерь для задач регрессии.\n",
    "\n",
    "Мы также мониторим в ходе обучения метрику MAE - Mean Absolute Error.\n",
    "\n",
    "\n",
    "### Валидация нашего подхода с использованием кросс-валидации\n",
    "Для оценки нейронной сети во время продолжения корректировки её параметров (кол-во эпох, например), мы могли бы просто разделить данные на тренировочную и контрольную выборки как прежде.\n",
    "\n",
    "Однако, поскольку мы имеем сравнительно немного данных,  и поэтому контрольная выборка может быть очень малой. Последствием этого является то, что данные на контрольной выборке могут сильно изменяться в зависимости от того, какие объекты мы выбираем для контроля, а какие для обучения, т.е. показания на контрольной выборке могут иметь высокий разброс, относительно разделения данных. Безусловно, это мешает оценить надежность модели.\n",
    "\n",
    "Хорошим подходом при решении подобных ситуация является кросс-валидации (K-fold cross-validation). \n",
    "Данные делятся на K частей, K-1 используется для обучения, 1 для тестирования. \n",
    "\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/k_fold_validation.png)\n",
    "\n",
    "А вот пример кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n",
      "processing fold # 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    model.fit(partial_train_data, partial_train_targets,\n",
    "              epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    # Evaluate the model on the validation data\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск кода с\n",
    "    num_epoch = 100\n",
    "приводит к сл. результатам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0595761856230177, 2.0456425553501241, 3.001954210866796, 2.4008110147891659]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3769959916572758"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разные запуски показывают разные показатели, но их среднее значительно более надежная величина."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
