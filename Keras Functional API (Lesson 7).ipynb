{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дополнительные инструменты глубокого обучения\n",
    "\n",
    "## Функциональный API Keras\n",
    "\n",
    "До сих пор, все рассмотренные в нашем курсе сети реализовывались с использованием последовательной модели Sequential.\n",
    "Sequential делает предположение о том, что сеть имеет в точности один вход и один выход, и она состоит из линейного стека слоев:\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/sequential_model.png)\n",
    "\n",
    "Это очень простое и популярное предположение: эта конфигурация по факту наиболее общая и покрывает большинство практических задач. Но тем не менее, оно слишком негибкое в ряде случаем.\n",
    "\n",
    "Так, некоторые сети требуют несколько независимых входов, некоторые требуют несколько выходов и некоторые имеют внутреннюю ветвистость между слоями, делая их похожими на графы слоев, а не на линейный стек слоев.\n",
    "\n",
    "Некоторые задачи, например, трубуют мультимодальные входы: они объедигяют данные, которые пришли из разных источников, обрабатывают каждый тип данных, используя разные види слоёв нейронной сети. Представьте глубоку модель, которая пытается предсказать  аиболее вероятную цену на рынке \"секонд-хэнда\" используя сл. вход:\n",
    "* Некоторые метаданные, предоставляемые пользователями (бренд, возраст, и т.д.);\n",
    "* Текстовое описание, предоставляемое пользователем;\n",
    "* Изображение товара;\n",
    "\n",
    "Если у нас есть только метаданные, можно использовать что-то похожее на унитарное кодирование и полносвязную сеть для предсказания цены. Если мы имеем только текстовое описание - используем RNN или 1D convnet. Если только картинку - мы можем использовать 2D convnet.\n",
    "\n",
    "**Но как заставить обрабатывать все три типа данных одновременно?**\n",
    "\n",
    "Наивный подход предполагает обучить 3 сепарабельные модели, и затем использовать взвешенное среднее их предсказаний. Однако, это субоптимальное решение, поскольку информация извлекаемая этими моделями является чрезвычайно избыточной.\n",
    "\n",
    "Более оптимальным способом является **совместное** обучение более точной модели данных с использованием модели, которая может рассматривать входные данные всех модальностей одновременно: модель с тремя входными ветвями:\n",
    "\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/3-input_model.png)\n",
    "\n",
    "Похожим образом, некоторые задачи требуют предсказания нескольких целевых атрибутов входных данных. Так, по тексту некоторого хужожественного произведения, например, хотят предсказать не только жанр (роман, триллер и т.д.), но и предсказать примерную дану, когда оно было написано. Разумеется, можно было бы обучить 2 нейронные сети, одну для жанра, а другую для даты. Но поскольку эти атрибты не являются статистически независимыми, можно построить лучшую модель для обучения **совместного предсказания** как жанра, так и даты в одно и тоже время.\n",
    "\n",
    "Такие совместные модели будут иметь два выходных параметра. Благодаря корреляции между жанром и датой, знание даты поможет модели обучиться более полным и точным репрезентациям пространства жанров и дат.\n",
    "\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/2-head_model.png) \n",
    "\n",
    "Также следует отметить, что много нейросетевых архитектур требует нелинейной сетевой топологии: т.е. сети структуризованные как ориентированные ациклические графы. \n",
    "\n",
    "Inception family of networks (Google), базируются на \"Inception modules\", где вход обрабатывается несколькими параллельными сверточными ветвями, чьи выходы затем объединяются в единый тензор. \n",
    "\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/inception_module.png)\n",
    "\n",
    "Есть также последние тренды в добавлении \"residual connections\" к модели, которые начинаются с семейства сетей ResNet. \n",
    "\n",
    "Residual connections состоят из перепроецирования предыдущих репрезентаций (reinjecting previous representations) в единый поток данных, добавлением предыдущего выходного тензора к более позднему тензору, что помогает предотвратить потерю информации по потоку обработки данных. \n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/residual_connection.png)\n",
    "\n",
    "Эти три важных кейса: \n",
    "* мультимодальный вход;\n",
    "* мультимодальный выход;\n",
    "* графовые представления моделей;\n",
    "\n",
    "**Невозможны** с использованием только последовательной модели Sequential в Keras. Но есть также другой, более общий и гибкий подход к использованию Keras: функциональный API.\n",
    "\n",
    "### Введение в функциональный API\n",
    "\n",
    "В функциональном API происходит прямое манипулирование тензорами, и вы используете слои как функции, который принимают тензоры и возвращают тензоры (отсюда и название функциональный).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Input, layers\n",
    "\n",
    "# This is a tensor.\n",
    "input_tensor = Input(shape=(32,))\n",
    "\n",
    "# A layer is a function.\n",
    "dense = layers.Dense(32, activation='relu')\n",
    "\n",
    "# A layer may be called on a tensor, and it returns a tensor.\n",
    "output_tensor = dense(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с простого примера:\n",
    "\n",
    "Рассмотрим простую Sequential модель и её эквивалент в функциональном API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "# A Sequential model, which you already know all about.\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Its functional equivalent.\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# The Model class turns an input tensor and output tensor into a model\n",
    "model = Model(input_tensor, output_tensor)\n",
    "\n",
    "# Let's look at it!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras будет извлекать каждый слой, вовлеченный в процесс, начиная с \n",
    "    input_tensor\n",
    "и заканчивая\n",
    "    output_tensor\n",
    "соединяя их вместе в подобие графовой структуры - Model.\n",
    "\n",
    "Разумеется, причина по которой она работает заключается в том, что output_tensor действительно получается путем многократного преобразования input_tensor.\n",
    "\n",
    "Если вы попытаетесь построить модель из входов и выходов, не связанных друг с другом, вы получите ошибку\n",
    "    RuntimeError:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"input_2:0\", shape=(?, 64), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ad090d276832>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0munrelated_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbad_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munrelated_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\oleg-\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\oleg-\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m   1780\u001b[0m                                 \u001b[1;34m'The following previous layers '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m                                 \u001b[1;34m'were accessed without issue: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1782\u001b[1;33m                                 str(layers_with_complete_input))\n\u001b[0m\u001b[0;32m   1783\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m                         \u001b[0mcomputable_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_2:0\", shape=(?, 64), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "unrelated_input = Input(shape=(32,))\n",
    "bad_model = model = Model(unrelated_input, output_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта ошибка в сущности говорит о том, что Keras не способе достичь input_1 из выходного тензора.\n",
    "\n",
    "При комбиляции, обучении или оценки такой модели Model, API тот же самый, что и при Sequential:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s - loss: 11.6939     \n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s - loss: 11.6167     \n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s - loss: 11.6061     \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s - loss: 11.5999     \n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s - loss: 11.5959     \n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s - loss: 11.5922     \n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s - loss: 11.5897     \n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s - loss: 11.5871     \n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s - loss: 11.5848     \n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s - loss: 11.5826     \n",
      "  32/1000 [..............................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# Generate dummy Numpy data to train on\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "# Train the model for 10 epochs\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель с несколькими входами\n",
    "\n",
    "Функциональный API может быть использован для построения моделей, использующих несколько входов.\n",
    "\n",
    "Обычно такие модели в некоторой части будут \"объединять\" входные ветви с использованием специального слоя, который комбинирует несколько тензоров, т.е. добавляет их, проводит конкатенацию и т.д.\n",
    "\n",
    "Это обычно выполняетя посредством операций объединения (merge operation) таких как:\n",
    "* keras.layers.add\n",
    "* keras.layers.concatenate\n",
    "* etc.\n",
    "\n",
    "Рассмотрим простую модель с несколькими входами: модель вопросно-ответной системы.\n",
    "\n",
    "Обычная вопросно-ответная модель имеет 2 входа: вопрос на естественном языке и текстовый сниппет (например, новостная статья), предоставляющая информацию, которая должна быть использована при ответе на вопрос. \n",
    "\n",
    "Модель должна произвести ответ: в самом простейшем случае это просто однословный ответ полученный через применение softmax над некоторым предобределенным словарем.\n",
    "\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/qa_model.png)\n",
    "\n",
    "Пример, как мы можем построить подобную модель с функциональным API:\n",
    "Мы устанавливаем 2 независимых ветви, кодируя текстовый вход и вопрос как вектора репрезентации, затем мы объединяем эти вектора и добавляет softmax классификатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# Our text input is a variable-length sequence of integers.\n",
    "# Note that we can optionally name our inputs!\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "\n",
    "# Which we embed into a sequence of vectors of size 64\n",
    "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
    "\n",
    "# Which we encoded in a single vector via a LSTM\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# Same process (with different layer instances) for the question\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# We then concatenate the encoded question and encoded text\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "# And we add a softmax classifier on top\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "# At model instantiation, we specify the two inputs and the output:\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы обучим такую модель?\n",
    "\n",
    "Есть два возможных API: вы можете передать как вход в модель список NumPy массивов, или вы можете ередать словарь, отображающий входные имена на NumPy массивам.\n",
    "\n",
    "Разумеется, последняя опция доступна лишь в том случае, если вы даете имена входам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 20\n",
    "\n",
    "# Let's generate some dummy Numpy data\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "\n",
    "# Answers are one-hot encoded, not integers\n",
    "answers = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size))\n",
    "\n",
    "# Fitting using a list of inputs\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "\n",
    "# Fitting using a dictionary of inputs (only if inputs were named!)\n",
    "model.fit({'text': text, 'question': question}, answers,\n",
    "          epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель с несколькими выходами\n",
    "\n",
    "Таким же образом, функциональный API может быть использован для построения моделей с несколькими выходами. Простой пример, который строит сеть, которая пытается одновременно предсказать разные свойства данных: например, сеть которая берет на вход серию постов из социальных медиа от одной анонимной персоны и пытается предсказать атрибуты:\n",
    "* возраст;\n",
    "* пол;\n",
    "* уровень дохода;\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/social_media_3-head_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# Note that we are giving names to the output layers.\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(input_posts, [age_prediction, income_prediction, gender_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение такой моедли требует возможности указать **разные функции потерь** для разных выходов сети:\n",
    "* возраст рассматривается как задача регрессии\n",
    "* пол как задача бинарной классификации, которая требует отдельной процедуры обучеия.\n",
    "\n",
    "Однако, градиентный спуск требует от нас минимизировать скаляр, мы должны скомбинировать эти функции потерь в единой значение чтобы обучать модель. Простейший способ комбинирования разных функций потерь состоит в том, чтобы просто суммировать их. В Keras вы можете либо задать список, или словарь функций потерь, который передается в compile для указания разных объектов для разных выходных значений и результирующие значения функции потерь суммируются в глобальные потери, которые минимизируются в процессе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "\n",
    "# Equivalent (only possible if you gave names to the output layers!):\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что также возможно назначить разную важность для функций потерь в их вкладе в финальну. потерю. Это полезно в частности если разные потери принимают значения на разных шкалах. Например, MSE потеря используемая для задачи возрастной регрессии может иметь типичное значение погрежности 305, в то время, как потрея перекрестной энтропии для задачи классификации гендера может достигать 0.1 \n",
    "\n",
    "В такой ситуации чтобы определить вклад разных функций потерь для более тщательного балансирования, мы назначим вес 10 для кросс-энтропии и вес 0.25 для MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 10.])\n",
    "\n",
    "# Equivalent (only possible if you gave names to the output layers!):\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'},\n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в случае моделей с несколькими входами, передача данных NumPy в модель для обучения может осуществляться либо через список массивов, либо через словарь массивов:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# age_targets, income_targets and gender_targets are assumed to be Numpy arrays\n",
    "model.fit(posts, [age_targets, income_targets, gender_targets],\n",
    "          epochs=10, batch_size=64)\n",
    "\n",
    "# Equivalent (only possible if you gave names to the output layers!):\n",
    "model.fit(posts, {'age': age_targets,\n",
    "                  'income': income_targets,\n",
    "                  'gender': gender_targets},\n",
    "          epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ориентированные ацикличные графы слоёв\n",
    "\n",
    "С фунциональным API можно реализовывать сети с очень сложной внутренней топологией. Нейронные сети в Keras позволяют определять произвольные **ориентированные ациклические графы** слоёв.\n",
    "\n",
    "Ацикличность важна - эти графы не могут содержать циклов! Возможны только петли (в рекуррентных связях) которые являются внутренней структурой рекуррентных слоев.\n",
    "\n",
    "Несколько общих компонент нейронных сетей реализованы как графы.\n",
    "* Inception modules;\n",
    "* residual connections;\n",
    "\n",
    "Для лучщего понимания как функциональный API строит графы слоев рассмотрим реализацию обоих архитектур в Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception modules\n",
    "\n",
    "Inception - популярная архитектура для сверточных нейронных сетей, разработанная Christian Szegedy в компании Google в 2013-2014 года, вдохновленная более ранней архитектурай \"network in network\". Она состоит из стека моулей, который сами по себе выглядят как малые независимые сети, разделенные на несколько параллельных ветвей. Наиболее базовая форма inception модуля имеет от 3 до 4 ветвей, начинающихся с конволюции 1x1, последующей 3x3 и заканчивающейся конкатенацией результирующих признаков. Эта настройка помогает сети независимо обучаться пространственным атрибутам и channel-wise атрибутам, которые более эффективны чем их совместное обучение. Более сложные версии Inception модуля также возможны, и как правило включают в себя операции пулинга, различные пространственные размеры конволюции например (5x5 вместо 3x3 для некоторых ветвей) и ветви без пространственной конволюции (1x1 конволюция). Пример:\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/inception_module.png)\n",
    "Реализация Inception модуля с функциональным API:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "# We assume the existence of a 4D input tensor `x`\n",
    "\n",
    "# Every branch has the same stride value (2), which is necessary to keep all\n",
    "# branch outputs the same size, so as to be able to concatenate them.\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x)\n",
    "\n",
    "# In this branch, the striding occurs in the spatial convolution layer\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "# In this branch, the striding occurs in the average pooling layer\n",
    "branch_c = layers.AveragePooling2D(3, strides=2, activation='relu')(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "\n",
    "# Finally, we concatenate the branch outputs to obtain the module output\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полная архитектура Inception V3 доступна в Keras как\n",
    "    keras.applications.inception_v3.InceptionV3\n",
    "включает веса предобученной модели на наборе данных ImageNet.\n",
    "\n",
    "Еще одной тесносвязанной моделью, доступной как часть Keras является модуль Xception (переводится как extreme inception), и являющийся архитектурой вдохновленной Inception. Он берет за основу идею разделения обучения по каналам (channel-wise) и по пространственным атрибутам (space-wise) и возводит её до логической экстремы - заменяя Incption модули углубленными разделимыми свертками (depthwise separable convolutions), состоящие из углубленных конволюций (пространственная конволюция, где каждый канал обрабатывается отдельно), за которыми следуют 1x1 конволюции - эффективная, экстремальная форма Inception модуля, где пространственные атрибуты и канальные атрибуты полностью разделены.\n",
    "\n",
    "Xception имеет примерно одинаковое число параметров как и Inception V3, но показывает лучшую производительность по времени выполнения и более высокую точность на ImageNet, благодаря более эффективному использованию параметров\n",
    "\n",
    "#### Residual connections\n",
    "\n",
    "Residual connections - очень общая графоподобная сетевая компонента, впервые описанная примерно в 2015 году. Эти архитектурные компоненты были введены He et al (Microsoft). Они обрабатывали 2 общие проблемы, возникающие в любой масштабируемой модели глубокого обучения: затухающий градиент и representation bottlenecks.\n",
    "\n",
    "Добавление residual connections **к любой модели имеющей более 10 слоев**, в общем случае, приводит к положительным результатам.\n",
    "\n",
    "Residual connection просто заключается в создание выхода на раннем слое, доступном как вход более позднего слоя, эффективно создавая кратчайший путь в последовательной сети. Вместо того, чтобы быть объединенным в более позднюю активацю, более ранний выход суммируется с более поздней активацией, которая предполагает что обе активации имеют равный размер. В случае разных размеров можно использовать линейное преобразование для перемасштабирования ранней активации в целевой размер.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация residual connection когда размеры карты атрибутов совпадают: использование идентичных residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "# We assume the existence of a 4D input tensor `x`\n",
    "x = ...\n",
    "# We apply some transformation to `x`\n",
    "y = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu')(y)\n",
    "\n",
    "# We add the original `x` back to the output features\n",
    "y = layers.add([y, x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация residual connections, когда размеры карты атрибутов отличаются: использование линейного преобращования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "# We assume the existence of a 4D input tensor `x`\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "# We use a 1x1 convolution to linearly downsample\n",
    "# the original `x` tensor to the same shape as `y`\n",
    "residual = layers.Conv2D(1, strides=2)(x)\n",
    "\n",
    "# We add the residual tensor back to the output features\n",
    "y = layers.add([y, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение весов в слоях\n",
    "\n",
    "Одной важной особенностью функционального API является возможность повторного использования экземпляра слоя несколько раз. Когда вы вызываете экземпляр слоя дважды, экземпляр создания нового слоя для каждого вызова вы повторно используете веса при каждом вызове. (When you call a layer instance twice, instance of instantiating a new layer for each call, you are reusing the same weights with every call.)\n",
    "\n",
    "Это позволяет построить модели имеющие разделяемые ветви - несколько ветвей, которые разделяют общие знания и выполняют те же операции, т.е. разделяют одни и те же репрезентации и используют эти репрезентации одновременно для разных множеств входных значений.\n",
    "\n",
    "В качестве примера можно привести модель, которая пытается оценить семантическую схожесть между двумя предложениями. Модель имеет 2 входа (2 предложения) и порождает вещественное число между 0 и 1 (0 - несвязанные предложения, 1 - предложения или идентичны, или чистая переформулировка друг друга). Такая модель может быть полезной во многих преложениях.\n",
    "\n",
    "В этом случае, 2 входных предложения взаимозаменяемы, поскольку семантическая схоесть является симметричным отношением - схожесть A и B идентична схожести B и A. По этим же причинам, нет смысла обучать 2 независимые модели для обработки каждого входного предложения. Вместо этого мы бы хотели обработать с помощью единой LSTM сети. Репрезентация LSTM слоя (его весов) будет обучаться на базе обоих входов одновременно. Это то что называется \"разделяемой LSTM\".\n",
    "\n",
    "Здесь мы будем реализовывать такую модель с использованием разделения весов слоев в функциональном API Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "# We instantiate a single LSTM layer, once\n",
    "lstm = layers.LSTM(32)\n",
    "\n",
    "# Building the left branch of the model\n",
    "# -------------------------------------\n",
    "\n",
    "# Inputs are variable-length sequences of vectors of size 128\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "# Building the right branch of the model\n",
    "# --------------------------------------\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "# When we call an existing layer instance,\n",
    "# we are reusing its weights\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "# Building the classifier on top\n",
    "# ------------------------------\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# Instantiating and training the model\n",
    "# ------------------------------------\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "# When you train such a model, the weights of the `lstm` layer\n",
    "# are updated based on both inputs.\n",
    "model.fit([left_data, right_data], targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Естественно, экземпляр слоя может использоваться более одного раза - его можно вызвать произвольное количество раз, каждый раз повторно используя одно и то же множество весов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модели как слои\n",
    "\n",
    "Важно то, что в функциональном API модели могут использоватькак если бы вы использовали слои - т.е. можно думать о модели как о \"большом слое\". Это верно как для класса Sequential так и о Model. Это означает что вы можете вызвать модель на входном тензоне и передать её выходному тензору.\n",
    "\n",
    "Пример: модели как слои, т.е. модели как функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если модель имеет несколько входных тензоров и несколько выъходных тензоров, она должна быть вызвана со списком тензоров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1, y2 = model([x1, x2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При вызове экземпляра модели, вы повторно используете веса модели - в точности как когда вы используете экземпляр слоя. Простым вызовом экземпляра, не важно, является ли экземпляр слоем или модель, будет всегда повторно использоваться уже существующая обученнаая репрезентация объекта - что достаточно интуитивно.\n",
    "\n",
    "Одним простым практическим примером является то, что Вы можете построить повторно используемый экземпляр модели - компьютерное зрение, которое использует на входе двойную камеру - две параллельные камеры, стоящие в отдалии несколько сантиметров друг от друга. \n",
    "\n",
    "По факту вы не нуждаетесь в двух параллельных моделях, для экстракции визуальных атрибутов от левой камеры и от правой камеры перед объедиением этих двух потоков. Такая низкоуровневая обработка может быть разделена среди двумя входами, т.е. выполняться слоями, которые используют одни и те же веса, и которые могут разделять одни и те же репрезентации.\n",
    "\n",
    "Пример в Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "\n",
    "# Our base image processing model with be the Xception network\n",
    "# (convolutional base only).\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "\n",
    "# Our inputs are 250x250 RGB images.\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "# We call the same vision model twice!\n",
    "left_features = xception_base(left_input)\n",
    "right_input = xception_base(right_input)\n",
    "\n",
    "# The merged features contain information from both\n",
    "# the right visual feed and the left visual feed\n",
    "merged_features = layers.concatenate([left_features, right_input], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Максимальная отдача от ваших моделей\n",
    "\n",
    "Попытка построения архитектур вслепую может \"хорошо\" работать в одном случае:\n",
    "![](http://memesmix.net/media/created/mfmd05.jpg)\n",
    "\n",
    "Но иногда требуется более эффективная модель, чем \"и так сойдет\" и которая будет давать великолепные результаты и даже побеждать в соревнованиях.\n",
    "\n",
    "Дадим краткий обзор техник для построения современных моделей глубокого обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Продвинутые архитектурные паттерны\n",
    "\n",
    "Мы уже познакомились с одним важным архитектурным паттерном прежде: residual connections. Рассмотрим еще два достаточно важных архитектурных паттерна.\n",
    "\n",
    "Эти паттерны особенно релевантны при построении высокопроизводительных глубоких сверточных сетей, но также могут быть найдены во многих других типах архитектур.\n",
    "\n",
    "### Batch Normalization\n",
    "\n",
    "Нормализация это широкая категория методов, которые направлены на то, чтобы сделать разные объекты, передаваемые модели машинного обучения более похожими друг на друга, что поможет модели обучиться и обобщить выводы на новые данные. Наиболее общей формой нормализаци иданных является центрорование данных около нулевого значения посредством вычитания среднего и преобразование к стандартному отклонению посредством деление данных на их стандартное отклонение. \n",
    "\n",
    "Фактически, делается предположение что данные сооветствуют нормальному распределению и обеспечивается чтобы это распределение было центрировано и масштабировано по стандартному отклонению:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_data = (data - np.mean(data, axis=...)) / np.std(data, axis=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предыдущих примерах мы проводили нормализацию данных перед передачей их в модели. Однако, нормализаиция данных должна по прежнему происходить после каждой операции преобразования в сети: даже если данные, идущие от Dense или Conv2D имеют нормализацию по стандартному отклонению, нет никаких оснований ожидать априори что они будут оставаться в той же форме после прохождения через жти слои.\n",
    "\n",
    "Batch normalization - это слой типа (BatchNormalization в Keras) введенный в 2015 году (Ioffe, Szegedy), способный адаптивно нормализовать данные, даже когда их среднее значение и дисперсия изменяются в процессе обучения. \n",
    "It works by internally maintaining an exponential moving average of the batch-wise mean and variance of the data seen during training. \n",
    "\n",
    "Основной эффект batch normalization состоит в том, что она помогаетраспространению градиента (gradient propagation) - подобно residual connections - и поэтому применима для глубоких сетей. Некоторые глубокие сети могут быть обучены только если они включают несколько слоев BatchNormalization.\n",
    "\n",
    "Например, BatchNormalization достаточно свободно используется в большинстве современных конволюционных архитектур, таких как ResNet50, InceptionV3 и Xception.\n",
    "\n",
    "Слой BatchNormalization обычно используется после конволюционного или полносвязного слоя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After a Conv layer:\n",
    "conv_model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "conv_model.add(layers.BatchNormalization())\n",
    "\n",
    "# After a Dense layer:\n",
    "dense_model.add(layers.Dense(32, activation='relu'))\n",
    "dense_model.add(layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слой BatchNormalization принимает на вход аргумент axis, который указывает оси атрибутов, которые должны быть нормализованы. По умолчанию это число равно -1, последняя оси во входном тензоре.\n",
    "\n",
    "Это корректное значение при использовании слоев Dense, слоев Conv1D, Conv2D, RNN слоев с data_format установленным на channels_last.\n",
    "\n",
    "Однако, в случае использования Conv2D с data_format установленым в значение channels_first, оси атрибутов имеют axis number 1, и axis аргумент в BatchNormalization должен быть соответственно установлен в 1.\n",
    "\n",
    "Недавним усовершенствованием обычно batch normalization была т.н. batch renormalization (2017). Он предлагает преимущества по сравнению с batch normalization, без каких либо очевидных затрат. Пока еще слишком рано говорить о преимуществах, и будет ли она вытеснять привычную регуляризацию.\n",
    "\n",
    "Совсем недавно Klambauer и др. ввели т.н. \"самонастраивающиеся нейронные сети\" (self-normaliung neural networks), которым удалось управлять нсохранением нормализации данных, после прохождения через Dense слой, посредством специфической функции активации (selu) и специфического инциализатора (lecun_normal. Эта схема выглядит интересной, но сейчас она ограничена полносвязными нейронными сетями.\n",
    "\n",
    "### Depthwise Separable Convolution\n",
    "\n",
    "Есть ли слой, который вы можете использовать в качестве замены для Conv2D который делает модель более легкой (меньшее число весовых параметров), быстрее (меньшее число операций с плавающей точкой)?\n",
    "\n",
    "Именно это делает слой: **depthwise separable convolution layer (SeparableConv2D)**.  \n",
    "\n",
    "Слой depthwise separable convolution выполняет пространственную свертку (spatial convolution) на каждом канале входа, независимо(!), перед смешиванием выходных каналов через \"поточечную\" свертку (1x1 convolution). Это эквивалентно разделению обучения пространственных атрибутов и обучению chanel-wise атрибут, что имеет смысл если допустить, что пространственные локации входа сильно коррелированы, в то время как разные каналы могут быть независимы. Слой требует намного меньше параметров, и включает в себя меньше вычислений, и результатом является меньшая и более быстрая модель.\n",
    "\n",
    "И поскольку это более репрезентативный и эффективный способ выполнения свертки, он, как правило, учит лучшим репрезентациям, используя меньше данных, что приводит к более эффективным моделям.\n",
    "\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/v-6/Figures/depthwise_separable_conv.png)\n",
    "\n",
    "Эти преимущества становятся особенно эффективными, когда мы обучаем небольшие модели с нуля на ограниченных данных.\n",
    "\n",
    "Например, построим легковесную depthwise separable convnet для задачи классификации изображений (softmax categorial classification) на небольшом наборе данных:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SeparableConv2D(32, activation='relu', input_shape=(height, width, channels)))\n",
    "model.add(SeparableConv2D(64, activation='relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(SeparableConv2D(64, activation='relu'))\n",
    "model.add(SeparableConv2D(128, activation='relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(SeparableConv2D(64, activation='relu'))\n",
    "model.add(SeparableConv2D(128, activation='relu'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to larger-scale models, depthwise separable convolutions are the basis of the Xception architecture, a high-performing convnet that comes packaged with Keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация гиперпараметров\n",
    "При построении моделей глубокого обучения, есть много решений которые нужно принять:\n",
    "* как много нужно выбрать слоев?\n",
    "* как много нейронов или фильтров должно быть на каждом слое?\n",
    "* какую функцию активации выбрать?\n",
    "* Нужно ли использовать BatchNormalization после уровня?\n",
    "* Какой dropout использовать?\n",
    "* ...\n",
    "\n",
    "Эти архитектурные параметры называются \"гиперпараметрами\", которые отличаются от параметров модели, которые настраиваются посредством обратного распространения ошибки.\n",
    "\n",
    "Формальных правил к оптимизации параметров не существует. Ваши первоначальные решения почти всегда субоптимальны, даже если у вас хорошая интуиция. Вы можете уточнить их, изменив их параметры вручную и повторно обучив свою модель - на самом деле это то, что большую часть времени проводят инженеры по машинному обучению и исследователи.\n",
    "\n",
    "Необходимо исследовательно пространство всевозможных решений автоматически и системно. Необходимо проводить поиск в пространстве архитектурных парамтров и находить наиболее лучшую модель эмпирически. Область автоматической оптимизации гиперпараметров - достаточно важная область исследований.\n",
    "\n",
    "Процесс оптимизации гиперпараметров обычно выглядит следующим образом:\n",
    "* Выберете набор гиперпараметров (автоматически);\n",
    "* Постройте соответствующую модель;\n",
    "* Обучите на тренировочных данных и измерьте производительность на валидационных данных;\n",
    "* Выберете следующее множество гиперпараметров для тестирования (автоматически);\n",
    "* Повторите;\n",
    "* ...\n",
    "* В конце концов измерьте производительность на тестовых данных.\n",
    "\n",
    "Ключевым моментов в этом процессе является алгоритм, который использует историю оценок производительности по серии гиперпараметров для выбора следующео набора гиперпараметров для оценки. Возможно множество техник: байесовская оптимизация, генетические алгоритмы и рандомизированный поиск...\n",
    "\n",
    "Обучение весов модели относительно простая задача - просто вычисляется функция потерь на mini-batches данных, затем используется алгоритм обратного распространения ошибки для \"продвижения\" весов в правильном направлении. Обновление гиперпараметров, с другой стороны, является достаточно тяжелой задачей.\n",
    "\n",
    "* Вычисление сигнала обратной связи (множество гиперпараметров приводит ли к более высокой производительности модели для данной задачи?) и может быть исключтельно дорогостоящим с точки зрения вычислительной мозности: он требует создания и обучения новой модели каждый раз с нуля;\n",
    "* Пространство гиперпараметров обычно делается как дискретные решения, и не является непрерывным и дифференцируемым. Пожтому невозможно применить градиентный спуск в пространстве гиперпараметров. Вместо этого нужно ориентироваться на техники оптимизации, не задействующие градиент, которые являются менее эффективными чем градиентный спуск.\n",
    "\n",
    "Из-за этих особенностей в настоящее время мы очень ограничены в инструментарии для оптимизации моделей. Часто выбор происходит посредством случайного поиска. ОДнако один инструмент, который можно применить - это *Hyperopt* - библиотека на Python для оптимизации гиперпараметров, которая внутри использует деревья для подбора. Еще одна библиотека называется Hyperas, которая интегрирует Hyperopt для использования с моделями Keras.\n",
    "\n",
    "Одной важной проблемой, которую надо держать в голове при автоматическом подборе параметров - переобучение на валидационной выборке. По мере обновления гиперпараметров на базе сигналов, вычисляемых при использовании валидационных данных, вы можете обучиться на валидационных данных и поэтому быстро переобучиться на них. Следует держать это в голове.\n",
    "\n",
    "Итак, оптимизация гиперпараметров эффективная техника, которая является необходимым требованием для получения современных моедлей практически для любой задачи или соревнования.\n",
    "\n",
    "\n",
    "### Ансамбли моделей"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
